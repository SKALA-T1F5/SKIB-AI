#!/usr/bin/env python3
"""
í†µí•© íŒŒì„œë¡œ ì²˜ë¦¬í•œ ê²°ê³¼ë¥¼ VectorDBì— ì—…ë¡œë“œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
python upload_to_vectordb.py "data/raw_docs/ìë™ì°¨ ë¦¬í¬íŠ¸.pdf"
"""

import os
import sys

from sentence_transformers import SentenceTransformer

from src.agents.document_analyzer.tools.unified_parser import parse_pdf_unified
from utils.naming import filename_to_collection

from .weaviate_utils import upload_chunk_to_collection

# ì„ë² ë”© ëª¨ë¸ ë¡œë”©
embedding_model = SentenceTransformer("BAAI/bge-base-en")


def upload_document_to_vectordb(pdf_path: str):
    """PDF ë¬¸ì„œë¥¼ íŒŒì‹±í•˜ê³  VectorDBì— ì—…ë¡œë“œ"""
    print(f"ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘: {pdf_path}")

    # 1. í†µí•© íŒŒì„œë¡œ ì²˜ë¦¬
    source_file = os.path.basename(pdf_path)
    # íŒŒì¼ëª…ì„ ì •ê·œí™”í•˜ì—¬ ì»¬ë ‰ì…˜ëª… ìƒì„±
    base_name = os.path.splitext(source_file)[0]
    collection_name = filename_to_collection(base_name)

    print(f"ğŸ·ï¸ ì»¬ë ‰ì…˜ëª…: {collection_name}")

    blocks = parse_pdf_unified(pdf_path, collection_name)

    # 2. ë¸”ë¡ íƒ€ì… í™•ì¸
    print(f"ğŸ“Š ì „ì²´ ë¸”ë¡ ìˆ˜: {len(blocks)}")
    for block_type in set(b.get("type", "unknown") for b in blocks):
        count = len([b for b in blocks if b.get("type") == block_type])
        print(f"   - {block_type}: {count}ê°œ")

    # í…ìŠ¤íŠ¸ ë¸”ë¡ë§Œ ì¶”ì¶œ (í‘œì™€ ì´ë¯¸ì§€ëŠ” ë©”íƒ€ë°ì´í„°ë¡œë§Œ í™œìš©)
    text_blocks = []
    for b in blocks:
        text_content = (
            b.get("text", "") or b.get("content", "") or b.get("source_text", "")
        )
        if text_content and text_content.strip():
            text_blocks.append(b)

    print(f"ğŸ“ ì—…ë¡œë“œí•  í…ìŠ¤íŠ¸ ë¸”ë¡: {len(text_blocks)}ê°œ")

    # 3. ê° ë¸”ë¡ì„ VectorDBì— ì—…ë¡œë“œ
    uploaded_count = 0

    for i, block in enumerate(text_blocks):
        # ì—¬ëŸ¬ í…ìŠ¤íŠ¸ í•„ë“œ í™•ì¸
        text_content = (
            block.get("text", "")
            or block.get("content", "")
            or block.get("source_text", "")
        ).strip()

        if not text_content:
            continue

        # ì²­í¬ ë©”íƒ€ë°ì´í„° êµ¬ì„±
        chunk_obj = {
            "chunk_id": f"{collection_name}_block_{i}",
            "chunk_type": block.get("type", "paragraph"),
            "section_title": block.get("section_title", ""),
            "source_text": text_content,
            "project": collection_name,
            "source": source_file,
        }

        try:
            # ë²¡í„° ì„ë² ë”© ìƒì„±
            vector = embedding_model.encode(text_content).tolist()

            # VectorDBì— ì—…ë¡œë“œ
            upload_chunk_to_collection(chunk_obj, vector, collection_name)
            uploaded_count += 1

        except Exception as e:
            print(f"âš ï¸ ë¸”ë¡ {i} ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

    print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_count}ê°œ ë¸”ë¡")
    return uploaded_count


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python upload_to_vectordb.py <pdf_path>")
        print("ì˜ˆì‹œ: python upload_to_vectordb.py 'data/raw_docs/ìë™ì°¨ ë¦¬í¬íŠ¸.pdf'")
        sys.exit(1)

    pdf_path = sys.argv[1]

    if not os.path.exists(pdf_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        sys.exit(1)

    print("ğŸš€ VectorDB ì—…ë¡œë“œ ì‹œì‘")
    print("=" * 50)

    try:
        upload_document_to_vectordb(pdf_path)
        print("\nğŸ‰ VectorDB ì—…ë¡œë“œ ì™„ë£Œ!")
        print("\nğŸ’¡ í™•ì¸ ë°©ë²•:")
        print("   python db/vectorDB/check_vectordb.py")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
