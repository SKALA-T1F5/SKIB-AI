"""
ChromaDB ì‚¬ìš© ì˜ˆì œ
"""

import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from db.vectorDB.chromaDB import (
    get_client,
    upload_documents,
    search_similar,
    list_collections,
    get_collection_info
)
from db.vectorDB.chromaDB.pipeline import ChromaDBPipeline


def example_basic_usage():
    """ê¸°ë³¸ ì‚¬ìš©ë²• ì˜ˆì œ"""
    print("ğŸ”§ ChromaDB ê¸°ë³¸ ì‚¬ìš©ë²•")
    print("=" * 50)
    
    # 1. í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í…ŒìŠ¤íŠ¸
    client = get_client()
    if client.test_connection():
        print("âœ… ChromaDB ì—°ê²° ì„±ê³µ")
    else:
        print("âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨")
        return
    
    # 2. ì»¬ë ‰ì…˜ ëª©ë¡ í™•ì¸
    collections = list_collections()
    print(f"ğŸ“‚ í˜„ì¬ ì»¬ë ‰ì…˜: {collections}")
    
    # 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì—…ë¡œë“œ
    test_blocks = [
        {
            "content": "ChromaDBëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.",
            "type": "text",
            "metadata": {"section": "intro", "page": 1}
        },
        {
            "content": "ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "type": "text", 
            "metadata": {"section": "features", "page": 1}
        }
    ]
    
    collection_name = "test_example"
    uploaded_count = upload_documents(test_blocks, collection_name, "example.txt")
    print(f"ğŸ“„ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_count}ê°œ")
    
    # 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    results = search_similar("ë²¡í„° ê²€ìƒ‰", collection_name, n_results=2)
    print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼:")
    for i, result in enumerate(results, 1):
        print(f"  [{i}] ìœ ì‚¬ë„: {result['similarity']:.3f}")
        print(f"      ë‚´ìš©: {result['content']}")
    
    # 5. ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
    info = get_collection_info(collection_name)
    print(f"ğŸ“Š ì»¬ë ‰ì…˜ ì •ë³´: {info['count']}ê°œ ë¬¸ì„œ")


def example_document_analyzer_integration():
    """DocumentAnalyzerì™€ì˜ í†µí•© ì˜ˆì œ"""
    print("\nğŸ”— DocumentAnalyzer í†µí•© ì˜ˆì œ")
    print("=" * 50)
    
    try:
        from src.agents.document_analyzer.agent import DocumentAnalyzerAgent
        
        # PDF íŒŒì¼ ê²½ë¡œ
        pdf_path = "data/raw_docs/Process íë¦„ë„_sample_250527.pdf"
        if not os.path.exists(pdf_path):
            print(f"âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
            return
        
        # DocumentAnalyzerë¡œ ë¬¸ì„œ ë¶„ì„
        collection_name = "example_integration"
        analyzer = DocumentAnalyzerAgent(collection_name, auto_upload_chromadb=True)
        
        print(f"ğŸ“‹ ë¬¸ì„œ ë¶„ì„ ì‹œì‘: {pdf_path}")
        result = analyzer.analyze_document(pdf_path, extract_keywords=True)
        
        print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"  ìƒíƒœ: {result.get('processing_status')}")
        print(f"  ì´ ë¸”ë¡: {result.get('total_blocks')}ê°œ")
        print(f"  ChromaDB ì—…ë¡œë“œ: {'âœ…' if result.get('chromadb_uploaded') else 'âŒ'}")
        print(f"  ì—…ë¡œë“œëœ ì²­í¬: {result.get('chromadb_upload_count')}ê°œ")
        
        # ì—…ë¡œë“œëœ ë°ì´í„°ë¡œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        if result.get('chromadb_uploaded'):
            print(f"\nğŸ” ì—…ë¡œë“œëœ ë°ì´í„° ê²€ìƒ‰:")
            results = search_similar("í”„ë¡œì„¸ìŠ¤", collection_name, n_results=3)
            
            for i, res in enumerate(results, 1):
                print(f"  [{i}] ìœ ì‚¬ë„: {res['similarity']:.3f}")
                print(f"      {res['content'][:60]}...")
        
    except ImportError:
        print("âŒ DocumentAnalyzerë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    except Exception as e:
        print(f"âŒ í†µí•© ì˜ˆì œ ì‹¤íŒ¨: {e}")


def example_pipeline_usage():
    """íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì˜ˆì œ"""
    print("\nğŸš€ ChromaDB íŒŒì´í”„ë¼ì¸ ì˜ˆì œ")
    print("=" * 50)
    
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = ChromaDBPipeline()
    
    # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ë¸”ë¡
    document_blocks = [
        {
            "content": "íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ë¬¸ì„œì…ë‹ˆë‹¤.",
            "type": "text",
            "metadata": {"section": "test", "page": 1}
        },
        {
            "content": "ChromaDB íŒŒì´í”„ë¼ì¸ì˜ ê¸°ëŠ¥ì„ ì‹œì—°í•©ë‹ˆë‹¤.",
            "type": "text",
            "metadata": {"section": "demo", "page": 1}
        }
    ]
    
    # ë¬¸ì„œ ì²˜ë¦¬ ë° ì—…ë¡œë“œ
    collection_name = "pipeline_example"
    result = pipeline.process_and_upload_document(
        document_blocks, 
        collection_name, 
        "pipeline_test.txt",
        recreate_collection=True
    )
    
    print(f"ğŸ“„ íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ê²°ê³¼:")
    print(f"  ìƒíƒœ: {result['status']}")
    print(f"  ì—…ë¡œë“œ: {result['uploaded_count']}/{result['total_blocks']}ê°œ")
    
    # ê²€ìƒ‰ ë° ë¶„ì„
    search_result = pipeline.search_and_analyze(
        "íŒŒì´í”„ë¼ì¸", 
        collection_name, 
        n_results=2
    )
    
    print(f"ğŸ” ê²€ìƒ‰ ë° ë¶„ì„ ê²°ê³¼:")
    print(f"  ê²°ê³¼ ìˆ˜: {search_result['result_count']}ê°œ")
    if search_result.get('analysis'):
        analysis = search_result['analysis']
        print(f"  í‰ê·  ìœ ì‚¬ë„: {analysis['avg_similarity']:.3f}")
    
    # íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸
    status = pipeline.get_pipeline_status()
    print(f"ğŸ“Š íŒŒì´í”„ë¼ì¸ ìƒíƒœ: {status.get('client_status')}")


def example_advanced_search():
    """ê³ ê¸‰ ê²€ìƒ‰ ì˜ˆì œ"""
    print("\nğŸ” ê³ ê¸‰ ê²€ìƒ‰ ì˜ˆì œ")
    print("=" * 50)
    
    from db.vectorDB.chromaDB.search import ChromaDBSearcher
    
    # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚¬ìš©
    collections = list_collections()
    if not collections:
        print("âŒ ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
        return
    
    collection_name = collections[0]
    searcher = ChromaDBSearcher()
    
    print(f"ğŸ“‚ ê²€ìƒ‰ ëŒ€ìƒ ì»¬ë ‰ì…˜: {collection_name}")
    
    # 1. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê²€ìƒ‰
    metadata_results = searcher.search_by_metadata(
        collection_name,
        where={"chunk_type": "heading"}
    )
    print(f"ğŸ“‹ í—¤ë”© íƒ€ì… ê²€ìƒ‰: {len(metadata_results)}ê°œ")
    
    # 2. íƒ€ì…ë³„ ê²€ìƒ‰
    text_results = searcher.search_by_type(collection_name, "text")
    print(f"ğŸ“ í…ìŠ¤íŠ¸ íƒ€ì… ê²€ìƒ‰: {len(text_results)}ê°œ")
    
    # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    hybrid_results = searcher.hybrid_search(
        "í”„ë¡œì„¸ìŠ¤",
        collection_name,
        n_results=3,
        metadata_filter={"chunk_type": "heading"},
        min_similarity=0.5
    )
    print(f"ğŸ”€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: {len(hybrid_results)}ê°œ")
    
    for i, result in enumerate(hybrid_results, 1):
        print(f"  [{i}] {result['content'][:50]}... (ìœ ì‚¬ë„: {result['similarity']:.3f})")


def main():
    """ëª¨ë“  ì˜ˆì œ ì‹¤í–‰"""
    print("ğŸ¯ ChromaDB ì‚¬ìš© ì˜ˆì œ")
    print("=" * 80)
    
    try:
        # ê¸°ë³¸ ì‚¬ìš©ë²•
        example_basic_usage()
        
        # DocumentAnalyzer í†µí•©
        example_document_analyzer_integration()
        
        # íŒŒì´í”„ë¼ì¸ ì‚¬ìš©ë²•
        example_pipeline_usage()
        
        # ê³ ê¸‰ ê²€ìƒ‰
        example_advanced_search()
        
        print(f"\nğŸ‰ ëª¨ë“  ì˜ˆì œ ì‹¤í–‰ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜ˆì œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()