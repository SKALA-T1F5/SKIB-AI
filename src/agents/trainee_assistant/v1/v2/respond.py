# agents/respond.py


from fastapi.responses import StreamingResponse
from konlpy.tag import Okt
from openai import AsyncOpenAI

from api.trainee_assistant.schemas.trainee_assistant import QuestionPayload
from config.settings import settings
from db.redisDB.session_manager import append_message, load_message_history
from db.vectorDB.chromaDB.search import ChromaDBSearcher
from src.agents.trainee_assistant.v1.v2.vector_search import (
    build_prompt_from_docs,
    search_chromadb,
)

openai_client = AsyncOpenAI(api_key=settings.api_key)


import logging

logger = logging.getLogger(__name__)


async def generate_answer(payload: QuestionPayload):
    user_id = payload.userId
    user_question = payload.question
    document_id = payload.documentId

    logger.info(
        f"ğŸ” [ì§ˆë¬¸ ìˆ˜ì‹ ] user_id: {user_id}, question: {user_question}, document_id: {document_id}"
    )

    # 1. Redis íˆìŠ¤í† ë¦¬ ë¡œë“œ
    history = await load_message_history(user_id)
    logger.debug(f"ğŸ“š [ë¶ˆëŸ¬ì˜¨ ì´ì „ íˆìŠ¤í† ë¦¬] {history}")
    history.append({"role": "user", "content": user_question})

    # 2. ChromaDBì—ì„œ ë¬¸ì„œ ê²€ìƒ‰
    logger.info(f"ğŸ§  [ChromaDB ê²€ìƒ‰ ì‹œì‘] collection={document_id}")
    chroma_searcher = ChromaDBSearcher()
    # 1. ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = extract_keywords(user_question)
    logger.info(f"ğŸ”‘ [ì§ˆë¬¸ í‚¤ì›Œë“œ ì¶”ì¶œ] {keywords}")

    # 2. ChromaDBì—ì„œ ê²€ìƒ‰ (ì „ì²´ ìœ ì‚¬í•œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°)
    docs = chroma_searcher.search_similar(
        query=user_question, collection_name=document_id
    )

    # 3. ìœ ì‚¬ë„ + í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§
    MIN_SIMILARITY = 0.75
    relevant_docs = [
        doc
        for doc in docs
        if doc["similarity"] >= MIN_SIMILARITY
        and any(k in doc["content"] for k in keywords)
    ]

    if relevant_docs:
        logger.info(f"ğŸ“„ [ê´€ë ¨ ë¬¸ì„œ ìˆìŒ] {len(relevant_docs)}ê°œ")

        # ğŸ‘‰ ë¬¸ì„œ ë‚´ìš©ì„ contextë¡œ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€
        context_prompt = build_prompt_from_docs(user_question, relevant_docs)
        context_role = {"role": "user", "content": context_prompt}

    else:
        logger.warning(
            f"âŒ [ë¬¸ì„œ ìœ ì‚¬ë„ ë¶€ì¡±] ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í•¨ (document_id: {document_id})"
        )
        # ğŸ‘‰ ìœ ì‚¬ ë¬¸ì„œê°€ ì•„ì˜ˆ ì—†ì„ ê²½ìš°, ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€ì²´
        context_prompt = (
            "âš ï¸ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\n\n"
            f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_question}"
        )
        context_role = {"role": "user", "content": context_prompt}

    # 3. GPT í˜¸ì¶œ
    logger.info("ğŸ¤– [GPT í˜¸ì¶œ ì‹œì‘]")
    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ì¹œì ˆí•œ í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. "
                    "ì‘ë‹µì€ 3~5ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°íˆ ì‘ì„±í•´ì£¼ì„¸ìš”."
                ),
            },
            *history,
            context_role,
        ],
    )
    assistant_reply = response.choices[0].message.content
    logger.info("ğŸ’¬ [GPT ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ]")

    # 4. Redis ì €ì¥
    await append_message(user_id, "user", user_question)
    await append_message(user_id, "assistant", assistant_reply)
    logger.info("ğŸ“ [ëŒ€í™” ì €ì¥ ì™„ë£Œ] Redis ì„¸ì…˜ ì €ì¥ë¨")

    return assistant_reply


async def generate_answer_stream(user_id: str, user_question: str):
    # 1. Redis ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
    history = await load_message_history(user_id)
    history.append({"role": "user", "content": user_question})

    # 2. ë¬¸ì„œ ê¸°ë°˜ context êµ¬ì„±
    docs = await search_chromadb(user_question)
    doc_context = (
        build_prompt_from_docs(user_question, docs)
        if docs
        else f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_question}"
    )

    system_prompt = (
        "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ìµí•œ í•™ìŠµ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. "
        "ë‹µë³€ì€ ê°„ê²°í•˜ê³  í•µì‹¬ì ìœ¼ë¡œ ì „ë‹¬í•´ì£¼ì„¸ìš”. ìµœëŒ€ 3~5ë¬¸ì¥ ì´ë‚´ë¡œ ì„¤ëª…í•˜ì„¸ìš”."
    )

    # 3. GPT ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ìš”ì²­
    response_stream = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            *history,
            {"role": "user", "content": doc_context},
        ],
        stream=True,
    )

    # 4. StreamingResponseë¡œ ë°˜í™˜
    async def event_stream():
        full_reply = ""
        async for chunk in response_stream:
            if chunk.choices[0].delta.content:
                token = chunk.choices[0].delta.content
                full_reply += token
                yield token  # í”„ë¡ íŠ¸ì— ì „ì†¡

        # ìŠ¤íŠ¸ë¦¬ë° ëë‚˜ê³  Redis ì €ì¥
        await append_message(user_id, "user", user_question)
        await append_message(user_id, "assistant", full_reply)

    return StreamingResponse(event_stream(), media_type="text/plain")


def extract_keywords(text: str, top_k: int = 5) -> list[str]:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ëª…ì‚¬ ë° ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ ì¶”ì¶œ
    """
    okt = Okt()
    words = [
        word
        for word, pos in okt.pos(text)
        if pos in ["Noun", "Alpha", "Verb"] and len(word) > 1
    ]

    # ë‹¨ìˆœ ë¹ˆë„ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ í‚¤ì›Œë“œ ì„ íƒ
    from collections import Counter

    most_common = Counter(words).most_common(top_k)
    return [word for word, _ in most_common]
