from typing import Dict, Any
from src.agents.trainee_assistant.models import MessageType
from src.agents.trainee_assistant.memory_manager import ConversationMemoryManager
from src.agents.trainee_assistant.context_manager import QuestionContextManager
from src.agents.trainee_assistant.rag_processor import RAGProcessor
from src.agents.trainee_assistant.tools import VectorSearchTool, WebSearchTool
from config.settings import settings

class TraineeAssistantAgent:
    """
    ì‹œí—˜ í›„ í•™ìŠµ ì§€ì›ì„ ìœ„í•œ Trainee Assistant AI ì—ì´ì „íŠ¸
    """
    
    def __init__(self, max_context_messages: int = 20, similarity_threshold: float = 0.7):
        # ê° ê¸°ëŠ¥ë³„ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.memory_manager = ConversationMemoryManager(max_context_messages)
        self.context_manager = QuestionContextManager()
        
         # ì´ˆê¸° ë„êµ¬ë“¤ì€ None, set_question_context ì‹œì ì— ìƒì„±
        self.vector_tool = None
        self.web_tool = WebSearchTool(
            api_key=settings.google_api_key,
            cx=settings.google_cx_id
        )
        self.rag_processor = None
        self.similarity_threshold = similarity_threshold
    
    def set_question_context(self, question_data: Dict[str, Any]):
        """í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°›ì€ ë¬¸ì œ ì •ë³´ë¥¼ ì„¤ì •í•˜ê³  ë„êµ¬ ì´ˆê¸°í™”"""
        self.context_manager.set_question_context(question_data)

        # ë¬¸ì„œëª… ê¸°ë°˜ìœ¼ë¡œ VectorSearchTool êµ¬ì„±
        document_name = question_data["document_name"]
        self.vector_tool = VectorSearchTool(document_name=document_name)
        
        # RAG Processor êµ¬ì„±
        self.rag_processor = RAGProcessor(
            similarity_threshold=self.similarity_threshold,
            vector_search_tool=self.vector_tool,
            web_search_tool=self.web_tool
        )
    
    async def process_message(self, user_message: str) -> Dict[str, Any]:
        """
        ðŸŸ¢ [1] ì‚¬ìš©ìž ë©”ì‹œì§€ ì²˜ë¦¬ ë° RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        ì›Œí¬í”Œë¡œìš° ì •ë³´ë„ í•¨ê»˜ ë°˜í™˜
        """
        # ì‚¬ìš©ìž ë©”ì‹œì§€ ì¶”ê°€
        self.memory_manager.add_message(MessageType.USER, user_message)
        
        # ðŸ”µ [2] info ë…¸ë“œ ì‹¤í–‰
        info_result = await self.rag_processor.info_node(user_message, self.memory_manager)
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        system_prompt = self.context_manager.get_system_prompt()
        
        # ë‹¤ìŒ ì•¡ì…˜ì— ë”°ë¼ ë¶„ê¸°
        if info_result["next_action"] == "use_vector_search":
            # ðŸŸ¡ [3A] vector_search ë…¸ë“œ ì‹¤í–‰
            response = await self.rag_processor.vector_search_node(
                user_message, 
                info_result["results"], 
                system_prompt
            )
        else:
            # ðŸŸ¡ [3B] web_search ë…¸ë“œ ì‹¤í–‰
            response = await self.rag_processor.web_search_node(
                user_message, 
                system_prompt, 
                self.memory_manager
            )
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì¶”ê°€
        self.memory_manager.add_message(MessageType.ASSISTANT, response)
        
        # ì›Œí¬í”Œë¡œìš° ì •ë³´ í¬í•¨í•˜ì—¬ ë°˜í™˜
        return {
            "response": response,
            "workflow_info": self.rag_processor.get_workflow_info()
        }
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """ëŒ€í™” ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        memory_summary = self.memory_manager.get_conversation_summary()
        context_summary = self.context_manager.get_context_summary()
        
        return {
            **memory_summary,
            "question_context": context_summary
        }
    
