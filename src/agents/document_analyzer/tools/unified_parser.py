"""
í†µí•© PDF íŒŒì„œ + GPT-4 Vision ì§ˆë¬¸ ìƒì„±
- Docling: í…ìŠ¤íŠ¸ êµ¬ì¡°í™” (paragraph, section, heading)
- pdfplumber + PyMuPDF: í‘œ ì¶”ì¶œ (ê°ì§€ + ë Œë”ë§)
- PyMuPDF: ì´ë¯¸ì§€ ì¶”ì¶œ (í’ˆì§ˆ í•„í„°ë§)
- GPT-4 Vision: ìë™ ì§ˆë¬¸ ìƒì„±
"""

import base64
import os
from typing import Dict, List

import fitz  # PyMuPDF
import pdfplumber

from src.agents.question_generator.tools.question_generator import QuestionGenerator
from utils.change_name import normalize_collection_name

from .image_extractor import _extract_quality_images
from .table_extractor import _extract_tables
from .text_extractor import _extract_structured_text_with_docling


def parse_pdf_unified(
    pdf_path: str,
    collection_name: str = None,
    generate_questions: bool = False,
    num_objective: int = 3,
    num_subjective: int = 3,
) -> List[Dict]:
    """
    í†µí•© PDF íŒŒì„œ: Docling í…ìŠ¤íŠ¸ êµ¬ì¡°í™” + ì„ íƒì  ìš”ì†Œ ì¶”ì¶œ + GPT-4 Vision ì§ˆë¬¸ ìƒì„±

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        collection_name: ì»¬ë ‰ì…˜ëª…
        generate_questions: GPT-4 Visionìœ¼ë¡œ ì§ˆë¬¸ ìƒì„± ì—¬ë¶€
        num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
        num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜

    Returns:
        List[Dict]: í†µí•© ì¶”ì¶œëœ ë¸”ë¡ë“¤ (ì§ˆë¬¸ ìƒì„± ì‹œ questions í•„ë“œ ì¶”ê°€)
    """
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
    if collection_name:
        normalized_name = normalize_collection_name(collection_name)
        IMAGE_SAVE_DIR = f"data/images/{normalized_name}"
    else:
        IMAGE_SAVE_DIR = "data/images/unified"
    os.makedirs(IMAGE_SAVE_DIR, exist_ok=True)
    print(f"ğŸ“„ í†µí•© íŒŒì„œë¡œ PDF ì²˜ë¦¬ ì¤‘: {pdf_path}")
    # 1. Doclingìœ¼ë¡œ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    print("ğŸ“ Doclingìœ¼ë¡œ í…ìŠ¤íŠ¸ êµ¬ì¡° ì¶”ì¶œ ì¤‘...")
    text_blocks = _extract_structured_text_with_docling(pdf_path)
    # 2. ì„ íƒì  ìš”ì†Œ ì¶”ì¶œ (í‘œ, ì´ë¯¸ì§€, ì°¨íŠ¸)
    print("ğŸ¯ ì„ íƒì  ìš”ì†Œ ì¶”ì¶œ ì¤‘...")
    visual_blocks = _extract_visual_elements(pdf_path, IMAGE_SAVE_DIR)
    # 3. ê²°í•© ë° ì •ë ¬
    all_blocks = text_blocks + visual_blocks
    # í˜ì´ì§€ë³„ë¡œ ì •ë ¬
    all_blocks.sort(key=lambda x: x.get("metadata", {}).get("page", 0))
    print(f"âœ… í†µí•© íŒŒì„œ ì™„ë£Œ:")
    print(f"  - ì´ ë¸”ë¡: {len(all_blocks)}ê°œ")
    print(
        f"  - í…ìŠ¤íŠ¸ ë¸”ë¡: {len([b for b in all_blocks if b.get('type') in ['paragraph', 'section', 'heading']])}ê°œ"
    )
    print(f"  - í‘œ: {len([b for b in all_blocks if b.get('type') == 'table'])}ê°œ")
    print(f"  - ì´ë¯¸ì§€: {len([b for b in all_blocks if b.get('type') == 'image'])}ê°œ")

    # 4. GPT-4 Vision ì§ˆë¬¸ ìƒì„± (ì„ íƒì )
    if generate_questions:
        print("\nğŸ¤– GPT-4 Vision ì§ˆë¬¸ ìƒì„± ì¤‘...")
        all_blocks = _generate_questions_for_blocks(
            all_blocks, IMAGE_SAVE_DIR, num_objective, num_subjective
        )

    return all_blocks


def _extract_visual_elements(pdf_path: str, image_save_dir: str) -> List[Dict]:
    """pdfplumber + PyMuPDFë¥¼ ì‚¬ìš©í•œ ì‹œê°ì  ìš”ì†Œ ì¶”ì¶œ"""
    blocks = []
    with pdfplumber.open(pdf_path) as pdf:
        pymupdf_doc = fitz.open(pdf_path)
        for page_num, (plumber_page, pymupdf_page) in enumerate(
            zip(pdf.pages, pymupdf_doc)
        ):
            page_no = page_num + 1
            print(f"  ğŸ“„ í˜ì´ì§€ {page_no} ì‹œê°ì  ìš”ì†Œ ì¶”ì¶œ ì¤‘...")
            # í‘œ ì¶”ì¶œ
            table_blocks = _extract_tables(
                plumber_page, pymupdf_page, page_no, image_save_dir
            )
            blocks.extend(table_blocks)
            # ì´ë¯¸ì§€ ì¶”ì¶œ
            image_blocks = _extract_quality_images(
                pymupdf_page, pymupdf_doc, page_no, image_save_dir
            )
            blocks.extend(image_blocks)
            # ì°¨íŠ¸ ì¶”ì¶œ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
            # from .chart_extractor import _extract_chart_areas
            # existing_bboxes = [b.get("metadata", {}).get("bbox") for b in table_blocks + image_blocks]
            # chart_blocks = _extract_chart_areas(plumber_page, pymupdf_page, page_no, image_save_dir, existing_bboxes)
            # blocks.extend(chart_blocks)
        pymupdf_doc.close()
    return blocks


def _generate_questions_for_blocks(
    blocks: List[Dict], image_save_dir: str, num_objective: int, num_subjective: int
) -> List[Dict]:
    """ë¸”ë¡ë“¤ì„ GPT-4 Vision ë©”ì‹œì§€ë¡œ ë³€í™˜í•˜ì—¬ ì§ˆë¬¸ ìƒì„±"""
    try:
        # QuestionGenerator ì‚¬ìš©
        question_generator = QuestionGenerator(image_save_dir)
        return question_generator.generate_questions_for_blocks(
            blocks, num_objective, num_subjective
        )
    except Exception as e:
        print(f"âŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return blocks


def _blocks_to_vision_chunks(
    blocks: List[Dict], image_save_dir: str, max_chunk_size: int = 15000
) -> List[Dict]:
    """ë¸”ë¡ë“¤ì„ GPT-4 Vision APIìš© ì²­í¬ë¡œ ë³€í™˜"""
    chunks = []
    current_chunk = {
        "messages": [],
        "metadata": {"pages": set(), "source": "unified_parser"},
        "block_indices": [],
        "current_length": 0,
    }

    def save_current_chunk():
        if current_chunk["messages"]:
            final_metadata = current_chunk["metadata"].copy()
            final_metadata["pages"] = sorted(list(final_metadata["pages"]))
            final_metadata["page"] = (
                final_metadata["pages"][0] if final_metadata["pages"] else 1
            )

            chunks.append(
                {
                    "messages": current_chunk["messages"].copy(),
                    "metadata": final_metadata,
                    "block_indices": current_chunk["block_indices"].copy(),
                }
            )

        current_chunk["messages"].clear()
        current_chunk["metadata"] = {"pages": set(), "source": "unified_parser"}
        current_chunk["block_indices"].clear()
        current_chunk["current_length"] = 0

    for block_idx, block in enumerate(blocks):
        block_type = block.get("type", "unknown")
        content = block.get("content", "")
        metadata = block.get("metadata", {})
        page_no = metadata.get("page", 1)

        # ë¸”ë¡ì„ ë©”ì‹œì§€ë¡œ ë³€í™˜
        message_content = None
        text_length = 0

        if block_type in ["paragraph", "heading", "section"]:
            text_content = str(content) if content else ""
            if text_content.strip():
                if block_type == "heading":
                    text_content = f"# {text_content}"
                elif block_type == "section":
                    text_content = f"## {text_content}"

                message_content = {"type": "text", "text": text_content}
                text_length = len(text_content)

        elif block_type == "table":
            # í‘œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if isinstance(content, dict) and "data" in content:
                table_text = _format_table_as_text(content)
                message_content = {"type": "text", "text": f"[Table]\n{table_text}"}
                text_length = len(table_text)

        elif block_type == "image":
            # ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
            image_path = os.path.join(image_save_dir, block.get("path", ""))
            if os.path.exists(image_path):
                try:
                    with open(image_path, "rb") as f:
                        encoded = base64.b64encode(f.read()).decode("utf-8")
                    message_content = {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{encoded}"},
                    }
                    text_length = 1000  # ì´ë¯¸ì§€ëŠ” ê³ ì • ê¸¸ì´ë¡œ ê³„ì‚°
                except Exception as e:
                    print(f"ì´ë¯¸ì§€ ì½ê¸° ì‹¤íŒ¨ {image_path}: {e}")
                    continue

        # ì²­í¬ í¬ê¸° í™•ì¸ ë° ì €ì¥
        if message_content:
            if (
                current_chunk["current_length"] + text_length > max_chunk_size
                and current_chunk["messages"]
            ):
                save_current_chunk()

            current_chunk["messages"].append(message_content)
            current_chunk["metadata"]["pages"].add(page_no)
            current_chunk["block_indices"].append(block_idx)
            current_chunk["current_length"] += text_length

    # ë§ˆì§€ë§‰ ì²­í¬ ì €ì¥
    save_current_chunk()

    return chunks


def _format_table_as_text(table_data: Dict) -> str:
    """í‘œ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not isinstance(table_data, dict) or "data" not in table_data:
        return str(table_data)

    headers = table_data.get("headers", [])
    data = table_data.get("data", [])

    if not data:
        return ""

    table_str = ""
    if headers:
        table_str += " | ".join(str(h) for h in headers) + "\n"
        table_str += "|" + "|".join([":---:"] * len(headers)) + "|\n"

    for row in data:
        table_str += " | ".join(str(cell) for cell in row) + "\n"

    return table_str.strip()


# í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
        collection_name = sys.argv[2] if len(sys.argv) > 2 else "test_unified"

        if os.path.exists(pdf_path):
            # ì§ˆë¬¸ ìƒì„± ì˜µì…˜ í™•ì¸
            generate_questions = len(sys.argv) > 3 and sys.argv[3].lower() == "true"

            blocks = parse_pdf_unified(
                pdf_path, collection_name, generate_questions=generate_questions
            )

            print(f"\nğŸ“Š í†µí•© íŒŒì„œ ê²°ê³¼:")
            print(f"  ì´ ë¸”ë¡: {len(blocks)}ê°œ")
            print(
                f"  í…ìŠ¤íŠ¸ ë¸”ë¡: {len([b for b in blocks if b.get('type') in ['paragraph', 'section', 'heading']])}ê°œ"
            )
            print(f"  í‘œ: {len([b for b in blocks if b.get('type') == 'table'])}ê°œ")
            print(f"  ì´ë¯¸ì§€: {len([b for b in blocks if b.get('type') == 'image'])}ê°œ")

            if generate_questions:
                total_questions = sum(len(b.get("questions", [])) for b in blocks)
                print(f"  ìƒì„±ëœ ì§ˆë¬¸: {total_questions}ê°œ")
        else:
            print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
    else:
        print(
            "ì‚¬ìš©ë²•: python unified_parser.py <pdf_path> [collection_name] [generate_questions:true/false]"
        )
        print("ì˜ˆì‹œ: python unified_parser.py 'document.pdf' 'test_collection' true")
