"""
TextAnalyzer - ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë¶„ì„ ë„êµ¬

ê¸°ì¡´ text_extractor.pyì˜ ë¡œì§ì„ BaseTool êµ¬ì¡°ë¡œ ë¦¬íŒ©í† ë§
"""

import os
from typing import Any, Dict, List, Optional

import pdfplumber
from docling.document_converter import DocumentConverter

from src.agents.base.tools import BaseTool


class TextAnalyzer(BaseTool):
    """
    í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë¶„ì„ ë„êµ¬

    ì£¼ìš” ê¸°ëŠ¥:
    - Doclingì„ ì´ìš©í•œ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    - pdfplumberë¥¼ ì´ìš©í•œ fallback í…ìŠ¤íŠ¸ ì¶”ì¶œ
    - í…ìŠ¤íŠ¸ íƒ€ì… ë¶„ë¥˜ (heading, section, paragraph)
    - í…ìŠ¤íŠ¸ ì •ì œ ë° ì „ì²˜ë¦¬
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)

        # ê¸°ë³¸ ì„¤ì •
        self.config.setdefault("min_text_length", 10)
        self.config.setdefault("use_docling", True)
        self.config.setdefault("fallback_to_pdfplumber", True)
        self.config.setdefault("clean_text", True)
        self.config.setdefault("classify_text_types", True)

    async def execute(self, pdf_path: str) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ ì¶”ì¶œì˜ ë©”ì¸ ì‹¤í–‰ ë©”ì„œë“œ

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ

        Returns:
            List[Dict]: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¸”ë¡ë“¤
        """
        if not self._initialized:
            await self.initialize()

        # 1. íŒŒì¼ ê²€ì¦
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")

        # 2. Docling ìš°ì„  ì‹œë„
        if self.config["use_docling"]:
            try:
                blocks = await self._extract_with_docling(pdf_path)
                if blocks:
                    print(f"  ğŸ“ Docling í…ìŠ¤íŠ¸ ë¸”ë¡: {len(blocks)}ê°œ")
                    return blocks
            except Exception as e:
                print(f"âš ï¸ Docling ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        # 3. pdfplumber fallback
        if self.config["fallback_to_pdfplumber"]:
            try:
                blocks = await self._extract_with_pdfplumber(pdf_path)
                print(f"  ğŸ“ pdfplumber í…ìŠ¤íŠ¸ ë¸”ë¡: {len(blocks)}ê°œ")
                return blocks
            except Exception as e:
                print(f"âŒ pdfplumber ì¶”ì¶œë„ ì‹¤íŒ¨: {e}")
                raise

        return []

    async def extract_simple_text(self, pdf_path: str) -> str:
        """
        ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì¶”ì¶œ (êµ¬ì¡° ì •ë³´ ì—†ì´)

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ

        Returns:
            str: ì¶”ì¶œëœ ì „ì²´ í…ìŠ¤íŠ¸
        """
        blocks = await self.execute(pdf_path)  # ë©”ì¸ execute ë©”ì„œë“œ ì‚¬ìš©

        # ëª¨ë“  í…ìŠ¤íŠ¸ ë¸”ë¡ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        text_parts = []
        for block in blocks:
            if block.get("type") in ["paragraph", "heading", "section"]:
                content = block.get("content") or block.get("title", "")
                if content:
                    text_parts.append(content)

        combined_text = "\n\n".join(text_parts)

        # í…ìŠ¤íŠ¸ ì •ì œ
        if self.config["clean_text"]:
            combined_text = await self.clean_text(combined_text)

        return combined_text

    async def classify_text_type(self, content: str) -> str:
        """
        í…ìŠ¤íŠ¸ íƒ€ì… ë¶„ë¥˜ (text_extractor.pyì˜ _classify_text_typeê³¼ í†µí•©ëœ ë¡œì§)

        Args:
            content: ë¶„ë¥˜í•  í…ìŠ¤íŠ¸

        Returns:
            str: í…ìŠ¤íŠ¸ íƒ€ì… ("heading", "section", "paragraph")
        """
        # text_extractor.pyì˜ _classify_text_type í•¨ìˆ˜ì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©
        from .text_extractor import _classify_text_type
        return _classify_text_type(content)

    async def clean_text(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ ì •ì œ

        Args:
            text: ì •ì œí•  í…ìŠ¤íŠ¸

        Returns:
            str: ì •ì œëœ í…ìŠ¤íŠ¸
        """
        if not text:
            return ""

        import re

        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r"\s+", " ", text)
        # ì—°ì†ëœ ì¤„ë°”ê¿ˆ ì œê±° (ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ)
        text = re.sub(r"\n{3,}", "\n\n", text)
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()

        return text

    # ë‚´ë¶€ í—¬í¼ ë©”ì„œë“œë“¤
    async def _extract_with_docling(self, pdf_path: str) -> List[Dict[str, Any]]:
        """Doclingì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        converter = DocumentConverter()
        result = converter.convert(pdf_path)
        document = result.document

        blocks = []

        # í…ìŠ¤íŠ¸ ê°ì²´ë“¤ ì²˜ë¦¬
        if hasattr(document, "texts"):
            for text_obj in document.texts:
                content = getattr(text_obj, "text", str(text_obj)).strip()
                if content and len(content) > self.config["min_text_length"]:
                    page_no = getattr(text_obj, "page_no", 0) + 1  # 1-indexed

                    # í…ìŠ¤íŠ¸ íƒ€ì… ë¶„ë¥˜
                    text_type = "paragraph"
                    if self.config["classify_text_types"]:
                        text_type = await self.classify_text_type(content)

                    blocks.append(
                        {
                            "type": text_type,
                            "content": content,
                            "metadata": {
                                "page": page_no,
                                "extraction_method": "docling_structured",
                                "source_file": os.path.basename(pdf_path),
                                "text_length": len(content),
                            },
                        }
                    )

        # ì œëª© ê°ì²´ë“¤ ì²˜ë¦¬
        if hasattr(document, "titles"):
            for title_obj in document.titles:  # type: ignore
                title = getattr(title_obj, "text", str(title_obj)).strip()
                if title:
                    page_no = getattr(title_obj, "page_no", 0) + 1

                    blocks.append(
                        {
                            "type": "section",
                            "title": title,
                            "content": title,  # content í•„ë“œë„ ì¶”ê°€ (ì¼ê´€ì„±ì„ ìœ„í•´)
                            "metadata": {
                                "page": page_no,
                                "extraction_method": "docling_section",
                                "source_file": os.path.basename(pdf_path),
                                "text_length": len(title),
                            },
                        }
                    )

        return blocks

    async def _extract_with_pdfplumber(self, pdf_path: str) -> List[Dict[str, Any]]:
        """pdfplumberë¥¼ ì‚¬ìš©í•œ fallback í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        blocks = []

        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                page_no = page_num + 1
                text_content = page.extract_text()

                if text_content and text_content.strip():
                    # ë¬¸ë‹¨ë³„ë¡œ ë¶„í• 
                    paragraphs = [
                        p.strip()
                        for p in text_content.split("\n\n")
                        if p.strip() and len(p) > 20
                    ]

                    for para in paragraphs:
                        # í…ìŠ¤íŠ¸ íƒ€ì… ë¶„ë¥˜
                        text_type = "paragraph"
                        if self.config["classify_text_types"]:
                            text_type = await self.classify_text_type(para)

                        blocks.append(
                            {
                                "type": text_type,
                                "content": para,
                                "metadata": {
                                    "page": page_no,
                                    "extraction_method": "pdfplumber_fallback",
                                    "source_file": os.path.basename(pdf_path),
                                    "text_length": len(para),
                                },
                            }
                        )

        return blocks

    def get_extraction_stats(self, blocks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì¶”ì¶œ í†µê³„ ì •ë³´ ìƒì„±"""
        if not blocks:
            return {}

        # íƒ€ì…ë³„ í†µê³„
        type_counts = {}
        total_text_length = 0
        pages = set()

        for block in blocks:
            block_type = block.get("type", "unknown")
            type_counts[block_type] = type_counts.get(block_type, 0) + 1

            content = block.get("content", "")
            total_text_length += len(content)

            page = block.get("metadata", {}).get("page")
            if page:
                pages.add(page)

        return {
            "total_blocks": len(blocks),
            "type_distribution": type_counts,
            "total_text_length": total_text_length,
            "average_block_length": total_text_length / len(blocks) if blocks else 0,
            "page_count": len(pages),
            "extraction_methods": list(
                set(
                    block.get("metadata", {}).get("extraction_method", "unknown")
                    for block in blocks
                )
            ),
        }
