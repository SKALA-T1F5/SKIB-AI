"""
ë¬¸ì œ ìƒì„± Agent
- GPT-4 Visionì„ ì‚¬ìš©í•œ ìë™ ë¬¸ì œ ìƒì„±
- í…ŒìŠ¤íŠ¸ ìš”ì•½ ë° ì„¤ì • íŒŒì¼ ìƒì„±
- ë¬¸ì œ ê²°ê³¼ ì €ì¥ ë° ê´€ë¦¬
"""

import json
import os
from datetime import datetime
from typing import Dict, List

from .tools.question_generator import QuestionGenerator


class QuestionGeneratorAgent:
    """ë¬¸ì œ ìƒì„± ì „ë¬¸ Agent"""

    def __init__(self, collection_name: str = None):
        self.collection_name = collection_name
        # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if collection_name:
            from utils.naming import filename_to_collection

            normalized_name = filename_to_collection(collection_name)
            self.image_save_dir = f"data/images/{normalized_name}"
        else:
            self.image_save_dir = "data/images/unified"
        self.question_generator = QuestionGenerator(self.image_save_dir)

    def generate_questions_from_blocks(
        self,
        blocks: List[Dict],
        num_objective: int = 3,
        num_subjective: int = 3,
        source_file: str = "document.pdf",
        keywords: List[str] = None,
        main_topics: List[str] = None,
        summary: str = "",
    ) -> Dict:
        """
        ë¸”ë¡ë“¤ë¡œë¶€í„° ë¬¸ì œ ìƒì„±

        Args:
            blocks: ë¬¸ì„œ ë¸”ë¡ë“¤
            num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
            num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
            source_file: ì›ë³¸ íŒŒì¼ëª…
            keywords: í‚¤ì›Œë“œ ëª©ë¡
            main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
            summary: ë¬¸ì„œ ìš”ì•½

        Returns:
            Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
        """
        print("ğŸ¤– QuestionGeneratorAgent ì‹œì‘")
        print(f"ğŸ¯ ëª©í‘œ: ê°ê´€ì‹ {num_objective}ê°œ, ì£¼ê´€ì‹ {num_subjective}ê°œ")

        try:
            # 1. ë¬¸ì œ ìƒì„±
            questions_blocks = self.question_generator.generate_questions_for_blocks(
                blocks, num_objective, num_subjective
            )

            # 2. ìƒì„±ëœ ë¬¸ì œ ì¶”ì¶œ
            all_questions = []
            for block in questions_blocks:
                if "questions" in block:
                    all_questions.extend(block["questions"])

            print(f"âœ… ì´ {len(all_questions)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")

            # 3. ê²°ê³¼ ì €ì¥
            result = self._save_question_results(
                questions=all_questions,
                source_file=source_file,
                keywords=keywords or [],
                main_topics=main_topics or [],
                summary=summary,
            )

            return result

        except Exception as e:
            print(f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "questions": [],
                "files_created": [],
            }

    def _save_question_results(
        self,
        questions: List[Dict],
        source_file: str,
        keywords: List[str],
        main_topics: List[str],
        summary: str,
    ) -> Dict:
        """ë¬¸ì œ ìƒì„± ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.splitext(os.path.basename(source_file))[0]
        files_created = []

        # 1. ìƒì„±ëœ ë¬¸ì œ íŒŒì¼ ì €ì¥
        questions_dir = "data/outputs/generated_questions"
        os.makedirs(questions_dir, exist_ok=True)

        questions_data = {
            "test_info": {
                "source_file": source_file,
                "collection_name": self.collection_name,
                "generation_date": datetime.now().isoformat(),
                "test_type": "auto_generated",
            },
            "question_summary": {
                "total_questions": len(questions),
                "objective_questions": len(
                    [q for q in questions if q.get("type") == "OBJECTIVE"]
                ),
                "subjective_questions": len(
                    [q for q in questions if q.get("type") == "SUBJECTIVE"]
                ),
                "difficulty_distribution": {
                    "easy": len(
                        [q for q in questions if q.get("difficulty_level") == "EASY"]
                    ),
                    "normal": len(
                        [q for q in questions if q.get("difficulty_level") == "NORMAL"]
                    ),
                    "hard": len(
                        [q for q in questions if q.get("difficulty_level") == "HARD"]
                    ),
                },
            },
            "questions": questions,
            "source_keywords": keywords,
            "source_topics": main_topics,
        }

        questions_file = f"{questions_dir}/{filename}_questions_{timestamp}.json"
        with open(questions_file, "w", encoding="utf-8") as f:
            json.dump(questions_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ìƒì„±ëœ ë¬¸ì œ ì €ì¥: {questions_file}")
        files_created.append(questions_file)

        # 2. í…ŒìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ìƒì„±
        summary_file = self._save_test_summary(
            questions, source_file, keywords, main_topics, summary, timestamp
        )
        if summary_file:
            files_created.append(summary_file)

        # 3. í…ŒìŠ¤íŠ¸ config íŒŒì¼ ìƒì„±
        config_file = self._save_test_config(questions, source_file, timestamp)
        if config_file:
            files_created.append(config_file)

        return {
            "status": "completed",
            "questions": questions,
            "total_questions": len(questions),
            "objective_count": len(
                [q for q in questions if q.get("type") == "OBJECTIVE"]
            ),
            "subjective_count": len(
                [q for q in questions if q.get("type") == "SUBJECTIVE"]
            ),
            "files_created": files_created,
            "collection_name": self.collection_name,
        }

    def _save_test_summary(
        self,
        questions: List[Dict],
        source_file: str,
        keywords: List[str],
        main_topics: List[str],
        summary: str,
        timestamp: str,
    ) -> str:
        """í…ŒìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ì €ì¥"""
        try:
            filename = os.path.splitext(os.path.basename(source_file))[0]
            summary_dir = "data/outputs/test_summaries"
            os.makedirs(summary_dir, exist_ok=True)

            objective_questions = [q for q in questions if q.get("type") == "OBJECTIVE"]
            subjective_questions = [
                q for q in questions if q.get("type") == "SUBJECTIVE"
            ]

            test_summary_data = {
                "test_overview": {
                    "title": f"{filename} - ìë™ ìƒì„± í…ŒìŠ¤íŠ¸",
                    "description": f"'{filename}' ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ìë™ ìƒì„±í•œ í‰ê°€ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                    "source_document": source_file,
                    "creation_date": datetime.now().isoformat(),
                    "test_type": "ì¢…í•© í‰ê°€",
                    "estimated_duration": f"{max(30, len(questions) * 2)}ë¶„",
                },
                "content_analysis": {
                    "document_summary": (
                        summary[:300] + "..." if len(summary) > 300 else summary
                    ),
                    "key_concepts": keywords[:10],
                    "main_topics": main_topics[:5],
                    "content_complexity": self._analyze_content_complexity(
                        keywords, main_topics, questions
                    ),
                },
                "test_structure": {
                    "total_questions": len(questions),
                    "question_breakdown": {
                        "objective": {
                            "count": len(objective_questions),
                            "percentage": (
                                round(
                                    len(objective_questions) / len(questions) * 100, 1
                                )
                                if questions
                                else 0
                            ),
                            "focus_areas": self._extract_question_topics(
                                objective_questions
                            ),
                        },
                        "subjective": {
                            "count": len(subjective_questions),
                            "percentage": (
                                round(
                                    len(subjective_questions) / len(questions) * 100, 1
                                )
                                if questions
                                else 0
                            ),
                            "focus_areas": self._extract_question_topics(
                                subjective_questions
                            ),
                        },
                    },
                    "difficulty_distribution": {
                        "easy": len(
                            [
                                q
                                for q in questions
                                if q.get("difficulty_level") == "EASY"
                            ]
                        ),
                        "normal": len(
                            [
                                q
                                for q in questions
                                if q.get("difficulty_level") == "NORMAL"
                            ]
                        ),
                        "hard": len(
                            [
                                q
                                for q in questions
                                if q.get("difficulty_level") == "HARD"
                            ]
                        ),
                    },
                },
                "assessment_guidelines": {
                    "objective_scoring": "ê° ê°ê´€ì‹ ë¬¸í•­ë‹¹ 1ì , ì •ë‹µ/ì˜¤ë‹µìœ¼ë¡œ ì±„ì ",
                    "subjective_scoring": "ë¬¸í•­ë³„ ë°°ì ì— ë”°ë¼ ë¶€ë¶„ ì ìˆ˜ ë¶€ì—¬ ê°€ëŠ¥",
                    "total_points": len(objective_questions)
                    + len(subjective_questions) * 5,
                    "passing_criteria": "ì´ì ì˜ 60% ì´ìƒ íšë“ ì‹œ í•©ê²©",
                },
            }

            summary_file = f"{summary_dir}/{filename}_test_summary_{timestamp}.json"
            with open(summary_file, "w", encoding="utf-8") as f:
                json.dump(test_summary_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ìš”ì•½ ì €ì¥: {summary_file}")
            return summary_file

        except Exception as e:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def _save_test_config(
        self, questions: List[Dict], source_file: str, timestamp: str
    ) -> str:
        """í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            filename = os.path.splitext(os.path.basename(source_file))[0]
            config_dir = "data/outputs/test_configs"
            os.makedirs(config_dir, exist_ok=True)

            objective_questions = [q for q in questions if q.get("type") == "OBJECTIVE"]
            subjective_questions = [
                q for q in questions if q.get("type") == "SUBJECTIVE"
            ]

            test_config_data = {
                "test_metadata": {
                    "config_version": "1.0",
                    "test_id": f"auto_test_{timestamp}",
                    "source_document": source_file,
                    "generation_system": "SKIB-AI Question Generator",
                    "creation_timestamp": datetime.now().isoformat(),
                },
                "test_settings": {
                    "time_limit": {
                        "total_minutes": max(30, len(questions) * 2),
                        "warning_at_minutes": max(25, len(questions) * 2 - 5),
                        "automatic_submit": True,
                    },
                    "question_settings": {
                        "randomize_order": False,
                        "allow_review": True,
                        "show_progress": True,
                    },
                },
                "scoring_configuration": {
                    "objective_questions": {
                        "points_per_question": 1,
                        "negative_marking": False,
                    },
                    "subjective_questions": {
                        "points_per_question": 5,
                        "allow_partial_credit": True,
                        "manual_grading_required": True,
                    },
                    "total_points": len(objective_questions)
                    + len(subjective_questions) * 5,
                },
            }

            config_file = f"{config_dir}/{filename}_test_config_{timestamp}.json"
            with open(config_file, "w", encoding="utf-8") as f:
                json.dump(test_config_data, f, ensure_ascii=False, indent=2)
            print(f"âš™ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • ì €ì¥: {config_file}")
            return config_file

        except Exception as e:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def _analyze_content_complexity(
        self, keywords: List[str], main_topics: List[str], questions: List[Dict]
    ) -> str:
        """ì½˜í…ì¸  ë³µì¡ë„ ë¶„ì„"""
        keywords_count = len(keywords)
        topics_count = len(main_topics)
        hard_questions = len(
            [q for q in questions if q.get("difficulty_level") == "HARD"]
        )

        if keywords_count > 10 and topics_count > 5 and hard_questions > 2:
            return "ê³ ê¸‰"
        elif keywords_count > 5 and topics_count > 3:
            return "ì¤‘ê¸‰"
        else:
            return "ì´ˆê¸‰"

    def _extract_question_topics(self, questions: List[Dict]) -> List[str]:
        """ë¬¸ì œì—ì„œ ì£¼ìš” ì£¼ì œ ì¶”ì¶œ"""
        topics = []
        for q in questions[:3]:  # ìƒìœ„ 3ê°œ ë¬¸ì œë§Œ ë¶„ì„
            question_text = q.get("question", "")
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            if "í”„ë¡œì„¸ìŠ¤" in question_text:
                topics.append("í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬")
            if "ì—…ë¬´" in question_text:
                topics.append("ì—…ë¬´ ì²˜ë¦¬")
            if "ê³„ì•½" in question_text:
                topics.append("ê³„ì•½ ê´€ë¦¬")
            if "ë“±ë¡" in question_text:
                topics.append("ë“±ë¡ ì ˆì°¨")

        return list(set(topics))[:3]  # ì¤‘ë³µ ì œê±° í›„ ìƒìœ„ 3ê°œ ë°˜í™˜


# í¸ì˜ í•¨ìˆ˜
def generate_questions_from_document(
    blocks: List[Dict],
    collection_name: str = None,
    num_objective: int = 3,
    num_subjective: int = 3,
    source_file: str = "document.pdf",
    keywords: List[str] = None,
    main_topics: List[str] = None,
    summary: str = "",
) -> Dict:
    """
    ë¬¸ì„œ ë¸”ë¡ë“¤ë¡œë¶€í„° ë¬¸ì œ ìƒì„± í¸ì˜ í•¨ìˆ˜

    Args:
        blocks: ë¬¸ì„œ ë¸”ë¡ë“¤
        collection_name: ì»¬ë ‰ì…˜ëª…
        num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
        num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
        source_file: ì›ë³¸ íŒŒì¼ëª…
        keywords: í‚¤ì›Œë“œ ëª©ë¡
        main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
        summary: ë¬¸ì„œ ìš”ì•½

    Returns:
        Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
    """
    agent = QuestionGeneratorAgent(collection_name)
    return agent.generate_questions_from_blocks(
        blocks,
        num_objective,
        num_subjective,
        source_file,
        keywords,
        main_topics,
        summary,
    )
