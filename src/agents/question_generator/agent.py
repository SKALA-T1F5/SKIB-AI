"""
Î¨∏Ï†ú ÏÉùÏÑ± Agent
- GPT-4 VisionÏùÑ ÏÇ¨Ïö©Ìïú ÏûêÎèô Î¨∏Ï†ú ÏÉùÏÑ±
- ÌÖåÏä§Ìä∏ ÏöîÏïΩ Î∞è ÏÑ§Ï†ï ÌååÏùº ÏÉùÏÑ±
- Î¨∏Ï†ú Í≤∞Í≥º Ï†ÄÏû• Î∞è Í¥ÄÎ¶¨
"""

import logging
from datetime import datetime
from typing import Any, Dict, List

from .tools.question_generator import QuestionGenerator
from .tools.result_saver import ResultSaver
from .tools.test_plan_handler import TestPlanHandler
from .tools.vector_search import VectorSearchHandler

logger = logging.getLogger(__name__)


class QuestionGeneratorAgent:
    """Î¨∏Ï†ú ÏÉùÏÑ± Ï†ÑÎ¨∏ Agent"""

    def __init__(self, collection_name: str | None = None):
        self.collection_name = collection_name
        # Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ ÏÑ§Ï†ï
        if collection_name is None:
            from utils.naming import filename_to_collection

            normalized_name = filename_to_collection(collection_name)
            self.image_save_dir = f"data/images/{normalized_name}"
        else:
            self.image_save_dir = "data/images/unified"
        self.question_generator = QuestionGenerator(self.image_save_dir)

        # Tools Ï¥àÍ∏∞Ìôî
        self.test_plan_handler = TestPlanHandler()
        self.vector_search_handler = VectorSearchHandler()
        self.result_saver = ResultSaver()

    def generate_enhanced_questions_from_test_plans(
        self,
        total_test_plan_path: str | None = None,
        document_test_plan_path: str | None = None,
        total_test_plan_data: Dict | None = None,
        document_test_plan_data: Dict | None = None,
    ) -> Dict[str, Any]:
        """
        ÌÖåÏä§Ìä∏ Í≥ÑÌöçÏùÑ Í∏∞Î∞òÏúºÎ°ú Ìñ•ÏÉÅÎêú Î¨∏Ï†ú ÏÉùÏÑ±

        Args:
            total_test_plan_path: Ï†ÑÏ≤¥ ÌÖåÏä§Ìä∏ Í≥ÑÌöç ÌååÏùº Í≤ΩÎ°ú (ÏÑ†ÌÉùÏÇ¨Ìï≠)
            document_test_plan_path: Î¨∏ÏÑúÎ≥Ñ ÌÖåÏä§Ìä∏ Í≥ÑÌöç ÌååÏùº Í≤ΩÎ°ú (ÏÑ†ÌÉùÏÇ¨Ìï≠)
            total_test_plan_data: Ï†ÑÏ≤¥ ÌÖåÏä§Ìä∏ Í≥ÑÌöç Îç∞Ïù¥ÌÑ∞ ÎîïÏÖîÎÑàÎ¶¨ (ÏÑ†ÌÉùÏÇ¨Ìï≠)
            document_test_plan_data: Î¨∏ÏÑúÎ≥Ñ ÌÖåÏä§Ìä∏ Í≥ÑÌöç Îç∞Ïù¥ÌÑ∞ ÎîïÏÖîÎÑàÎ¶¨ (ÏÑ†ÌÉùÏÇ¨Ìï≠)
        Returns:
            Dict: Î¨∏Ï†ú ÏÉùÏÑ± Í≤∞Í≥º
        """
        logger.info("üöÄ Ìñ•ÏÉÅÎêú Î¨∏Ï†ú ÏÉùÏÑ±Í∏∞ ÏãúÏûë")

        # 1. Test Plan Î°úÎìú (Ïö∞ÏÑ†ÏàúÏúÑ: Îç∞Ïù¥ÌÑ∞ > Í≤ΩÎ°ú > ÏûêÎèô Í≤ÄÏÉâ)
        total_plan = None
        document_plan = None

        if total_test_plan_data and document_test_plan_data:
            # ÏßÅÏ†ë ÎîïÏÖîÎÑàÎ¶¨ Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïö©
            total_plan = total_test_plan_data
            document_plan = document_test_plan_data
            logger.info("üìã Test Plan Îç∞Ïù¥ÌÑ∞Î•º ÏßÅÏ†ë ÎîïÏÖîÎÑàÎ¶¨Î°ú Î∞õÏùå")
        elif total_test_plan_path and document_test_plan_path:
            # ÏßÄÏ†ïÎêú Í≤ΩÎ°úÏóêÏÑú Î°úÎìú -> Local TestÏö©
            total_plan, document_plan = self.test_plan_handler.load_specific_test_plans(
                total_test_plan_path, document_test_plan_path
            )
            if not total_plan or not document_plan:
                return {"status": "failed", "error": "ÏßÄÏ†ïÎêú Test plan ÌååÏùº Î°úÎìú Ïã§Ìå®"}
        else:
            # ÏûêÎèôÏúºÎ°ú ÏµúÏã† ÌååÏùº Ï∞æÍ∏∞
            total_plan, document_plan = self.test_plan_handler.load_latest_test_plans()
            if not total_plan or not document_plan:
                return {
                    "status": "failed",
                    "error": "Test plan ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.",
                }

        all_generated_questions = []
        generation_summary = {
            "total_documents": len(document_plan.get("document_plans", [])),
            "documents_processed": [],
            "total_questions_generated": 0,
            "basic_questions": 0,
            "extra_questions": 0,
        }

        # Ï†ÑÏ≤¥ ÌÖåÏä§Ìä∏ Í≥ÑÌöçÏóêÏÑú ÎÇúÏù¥ÎèÑ Ï∂îÏ∂ú
        difficulty = total_plan.get("test_plan", {}).get("difficulty_level", "NORMAL")

        # 2. Í∞Å Î¨∏ÏÑúÎ≥ÑÎ°ú Î¨∏Ï†ú ÏÉùÏÑ±
        for doc_plan in document_plan.get("document_plans", []):
            document_name = doc_plan.get("document_name", "Unknown")
            document_id = doc_plan.get("document_id", None)
            keywords = doc_plan.get("keywords", [])
            recommended = doc_plan.get("recommended_questions", {})

            logger.info(f"\nüìÑ Î¨∏ÏÑú Ï≤òÎ¶¨: {document_name}")
            logger.info(f"üîë ÌÇ§ÏõåÎìú: {', '.join(keywords)}")
            logger.info(
                f"üìä Ï∂îÏ≤ú Î¨∏Ï†úÏàò: Í∞ùÍ¥ÄÏãù {recommended.get('objective', 0)}Í∞ú, Ï£ºÍ¥ÄÏãù {recommended.get('subjective', 0)}Í∞ú"
            )
            logger.info(f"üéØ ÎÇúÏù¥ÎèÑ: {difficulty}")

            # VectorDBÏóêÏÑú ÌÇ§ÏõåÎìú Í¥ÄÎ†® ÏΩòÌÖêÏ∏† Í≤ÄÏÉâ (Î¨∏ÏÑúÎ™ÖÏùÑ ÏûêÎèôÏúºÎ°ú collectionÎ™ÖÏúºÎ°ú Î≥ÄÌôò)
            if document_name:
                related_content = (
                    self.vector_search_handler.search_keywords_in_collection(
                        keywords, document_name
                    )
                )
            else:
                # Î¨∏ÏÑúÎ™ÖÏù¥ ÏóÜÎäî Í≤ΩÏö∞ fallback Ïª¨Î†âÏÖòÎì§ÏóêÏÑú Í≤ÄÏÉâ
                related_content = (
                    self.vector_search_handler.search_with_fallback_collections(
                        keywords=keywords, primary_document_name=""
                    )
                )

            doc_questions = []

            # 3. Í∏∞Î≥∏ Î¨∏Ï†ú ÏÉùÏÑ± (Ï∂îÏ≤ú Î¨∏Ï†úÏàò)
            basic_questions = self._generate_questions_with_context(
                keywords=keywords,
                related_content=related_content,
                document_name=document_name,
                document_id=document_id,
                num_objective=recommended.get("objective", 0),
                num_subjective=recommended.get("subjective", 0),
                question_type="BASIC",
                difficulty=difficulty,
                total_test_plan=total_plan,
                document_test_plan=doc_plan,
            )
            doc_questions.extend(basic_questions)

            # 4. Ïó¨Î∂Ñ Î¨∏Ï†ú ÏÉùÏÑ± (ÌÇ§ÏõåÎìúÎ≥Ñ 2Î¨∏Ï†úÏî©)
            extra_objective, extra_subjective = (
                self.test_plan_handler.calculate_extra_questions(keywords)
            )

            if extra_objective > 0 or extra_subjective > 0:
                logger.info(
                    f"  üéØ Ïó¨Î∂Ñ Î¨∏Ï†ú ÏÉùÏÑ±: Í∞ùÍ¥ÄÏãù {extra_objective}Í∞ú, Ï£ºÍ¥ÄÏãù {extra_subjective}Í∞ú"
                )

                extra_questions = self._generate_questions_with_context(
                    keywords=keywords,
                    related_content=related_content,
                    document_name=document_name,
                    document_id=document_id,
                    num_objective=extra_objective,
                    num_subjective=extra_subjective,
                    question_type="EXTRA",
                    difficulty=difficulty,
                    total_test_plan=total_plan,
                    document_test_plan=doc_plan,
                )
                doc_questions.extend(extra_questions)

            # Í≤∞Í≥º ÏöîÏïΩ
            basic_count = len(basic_questions)
            extra_count = len(doc_questions) - basic_count

            generation_summary["documents_processed"].append(
                {
                    "document_name": document_name,
                    "keywords": keywords,
                    "basic_questions": basic_count,
                    "extra_questions": extra_count,
                    "total_questions": len(doc_questions),
                }
            )

            generation_summary["basic_questions"] += basic_count
            generation_summary["extra_questions"] += extra_count

            all_generated_questions.extend(doc_questions)

            logger.info(
                f"  ‚úÖ '{document_name}' Î¨∏Ï†ú ÏÉùÏÑ± ÏôÑÎ£å: Í∏∞Î≥∏ {basic_count}Í∞ú + Ïó¨Î∂Ñ {extra_count}Í∞ú = Ï¥ù {len(doc_questions)}Í∞ú"
            )

        generation_summary["total_questions_generated"] = len(all_generated_questions)

        # 5. Í≤∞Í≥º Ï†ÄÏû•
        result = self.result_saver.save_enhanced_questions(
            questions=all_generated_questions,
            summary=generation_summary,
            total_plan=total_plan,
            document_plan=document_plan,
        )

        return result

    def _generate_questions_with_context(
        self,
        keywords: List[str],
        related_content: List[Dict],
        document_name: str,
        document_id: int,
        num_objective: int,
        num_subjective: int,
        question_type: str = "BASIC",
        difficulty: str = "NORMAL",
        total_test_plan: Dict | None = None,
        document_test_plan: Dict | None = None,
    ) -> List[Dict]:
        """ÏΩòÌÖçÏä§Ìä∏Î•º ÌôúÏö©Ìïú Î¨∏Ï†ú ÏÉùÏÑ± (Í∏∞Ï°¥ QuestionGenerator ÌôúÏö©)"""
        if num_objective == 0 and num_subjective == 0:
            return []

        try:
            # Í¥ÄÎ†® ÏΩòÌÖêÏ∏†Î•º Î∏îÎ°ù ÌòïÌÉúÎ°ú Î≥ÄÌôò
            context_blocks = self._convert_content_to_blocks(related_content, keywords)

            # TODO: ChromaDB Ïó∞Í≤∞ ÎêòÎ©¥ Ïù¥Í±∞ ÌïòÍ∏∞
            # if not context_blocks:
            #     logger.warning(f"  ‚ö†Ô∏è ÏΩòÌÖçÏä§Ìä∏ Î∏îÎ°ùÏùÑ ÏÉùÏÑ±Ìï† Ïàò ÏóÜÏäµÎãàÎã§.")
            #     return []

            # Í∏∞Ï°¥ QuestionGenerator ÌôúÏö©
            # TODO: context_blocks overwrite -> WHY?
            context_blocks = self.question_generator.generate_questions_for_blocks(
                blocks=context_blocks,
                num_objective=num_objective,
                num_subjective=num_subjective,
                difficulty=difficulty,
                total_test_plan=total_test_plan or {},
                document_test_plan=document_test_plan or {},
            )

            # ÏÉùÏÑ±Îêú Î¨∏Ï†ú Ï∂îÏ∂ú Î∞è Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
            questions = []
            for block in context_blocks:
                if "questions" in block:
                    for question in block["questions"]:
                        # Î¨∏Ï†úÏóêÏÑú Ïã§Ï†ú ÏÇ¨Ïö©Îêú ÌÇ§ÏõåÎìú Ï∂îÏ∂ú
                        used_keywords = self._extract_used_keywords(question, keywords)

                        # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
                        question["generation_type"] = question_type
                        question["document_name"] = document_name
                        question["document_id"] = document_id
                        question["generated_at"] = datetime.now().isoformat()
                        question["source_keywords"] = used_keywords
                        questions.append(question)

            logger.info(f"  ‚úÖ {len(questions)}Í∞ú {question_type} Î¨∏Ï†ú ÏÉùÏÑ± ÏôÑÎ£å")
            return questions

        except Exception as e:
            logger.error(f"  ‚ùå {question_type} Î¨∏Ï†ú ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return []

    def _convert_content_to_blocks(
        self, related_content: List[Dict], keywords: List[str]
    ) -> List[Dict]:
        """Í¥ÄÎ†® ÏΩòÌÖêÏ∏†Î•º Î∏îÎ°ù ÌòïÌÉúÎ°ú Î≥ÄÌôò"""
        return self.vector_search_handler.convert_content_to_blocks(
            related_content, keywords
        )

    # TODO Î¨∏Ï†úÏóêÏÑú Ïã§Ï†ú ÏÇ¨Ïö©Îêú ÌÇ§ÏõåÎìú Ï∂îÏ∂ú Î°úÏßÅ Ï†êÍ≤Ä ÌïÑÏöî -> [] Ï≤òÎ¶¨ Îê†Îïå ÏûàÏùå.
    def _extract_used_keywords(
        self, question: Dict, available_keywords: List[str]
    ) -> List[str]:
        """
        Î¨∏Ï†úÏóêÏÑú Ïã§Ï†ú ÏÇ¨Ïö©Îêú ÌÇ§ÏõåÎìúÎßå Ï∂îÏ∂ú

        Args:
            question: ÏÉùÏÑ±Îêú Î¨∏Ï†ú ÎîïÏÖîÎÑàÎ¶¨
            available_keywords: ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌÇ§ÏõåÎìú Î™©Î°ù

        Returns:
            List[str]: Ïã§Ï†ú Î¨∏Ï†úÏóêÏÑú ÏÇ¨Ïö©Îêú ÌÇ§ÏõåÎìúÎì§
        """
        used_keywords = []

        # Î¨∏Ï†ú ÌÖçÏä§Ìä∏ÏóêÏÑú Í≤ÄÏÉâÌï† ÌïÑÎìúÎì§
        text_fields = []

        # Î¨∏Ï†ú Î≥∏Î¨∏
        if question.get("question"):
            text_fields.append(question["question"])

        # Í∞ùÍ¥ÄÏãù ÏÑ†ÌÉùÏßÄ
        if question.get("options"):
            text_fields.extend(question["options"])

        # Ï†ïÎãµ
        if question.get("answer"):
            text_fields.append(question["answer"])

        # Ìï¥ÏÑ§
        if question.get("explanation"):
            text_fields.append(question["explanation"])

        # Î™®Îì† ÌÖçÏä§Ìä∏Î•º ÌïòÎÇòÎ°ú Ìï©ÏπòÍ∏∞
        combined_text = " ".join(text_fields).lower()

        # Í∞Å ÌÇ§ÏõåÎìúÍ∞Ä Î¨∏Ï†ú ÌÖçÏä§Ìä∏Ïóê Ìè¨Ìï®ÎêòÏñ¥ ÏûàÎäîÏßÄ ÌôïÏù∏
        for keyword in available_keywords:
            # ÌÇ§ÏõåÎìúÎ•º ÏÜåÎ¨∏ÏûêÎ°ú Î≥ÄÌôòÌïòÏó¨ Í≤ÄÏÉâ (ÎåÄÏÜåÎ¨∏Ïûê Î¨¥Ïãú)
            if keyword.lower() in combined_text:
                used_keywords.append(keyword)
            # ÌÇ§ÏõåÎìúÏùò ÏùºÎ∂ÄÎ∂ÑÏù¥ Ìè¨Ìï®Îêú Í≤ΩÏö∞ÎèÑ ÌôïÏù∏ (Ïòà: "ServiceFLOW" -> "serviceflow")
            elif keyword.lower().replace(" ", "").replace("_", "").replace(
                "-", ""
            ) in combined_text.replace(" ", "").replace("_", "").replace("-", ""):
                used_keywords.append(keyword)

        return used_keywords

    def generate_questions_from_contexts(
        self,
        contexts: List[Dict[str, Any]],
        target_questions: Dict[str, int],
        document_metadata: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        Î∞∞Ïπò Ï≤òÎ¶¨Ïö© Ïª®ÌÖçÏä§Ìä∏ Í∏∞Î∞ò Î¨∏Ï†ú ÏÉùÏÑ±

        Args:
            contexts: VectorDB Í≤ÄÏÉâÎêú Ïª®ÌÖçÏä§Ìä∏ Î™©Î°ù
            target_questions: {"objective": 3, "subjective": 2}
            document_metadata: {
                "document_name": "doc.pdf",
                "document_id": 101,
                "keywords": ["keyword1", "keyword2"],
                "difficulty": "medium"
            }

        Returns:
            Dict: {
                "status": "success"|"failed",
                "questions": List[Dict],
                "metadata": Dict
            }
        """
        logger.info(f"ü§ñ Î∞∞Ïπò Î¨∏Ï†ú ÏÉùÏÑ± ÏãúÏûë: {target_questions}")

        try:
            # 1. Ïª®ÌÖçÏä§Ìä∏Î•º Î∏îÎ°ù ÌòïÌÉúÎ°ú Î≥ÄÌôò
            keywords = document_metadata.get("keywords", [])
            blocks = self.vector_search_handler.convert_content_to_blocks(
                contexts, keywords
            )

            if not blocks:
                return {
                    "status": "failed",
                    "error": "Ïª®ÌÖçÏä§Ìä∏Î•º Î∏îÎ°ùÏúºÎ°ú Î≥ÄÌôòÌï† Ïàò ÏóÜÏäµÎãàÎã§",
                    "questions": [],
                    "metadata": {"contexts_count": len(contexts)},
                }

            # 2. Î¨∏Ï†ú ÏÉùÏÑ± ÏÑ§Ï†ï
            num_objective = target_questions.get("objective", 0)
            num_subjective = target_questions.get("subjective", 0)
            difficulty = document_metadata.get("difficulty", "NORMAL")

            # 3. Í∏∞Ï°¥ QuestionGenerator ÌôúÏö©
            questions_blocks = self.question_generator.generate_questions_for_blocks(
                blocks=blocks,
                num_objective=num_objective,
                num_subjective=num_subjective,
                difficulty=difficulty.upper(),
            )

            # 4. ÏÉùÏÑ±Îêú Î¨∏Ï†ú Ï∂îÏ∂ú Î∞è Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
            all_questions = []
            for block in questions_blocks:
                if "questions" in block:
                    for question in block["questions"]:
                        # Î∞∞Ïπò Ï≤òÎ¶¨Ïö© Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
                        question["document_name"] = document_metadata.get(
                            "document_name", ""
                        )
                        question["document_id"] = document_metadata.get(
                            "document_id", 0
                        )
                        question["generated_at"] = datetime.now().isoformat()
                        question["generation_type"] = "BATCH"
                        question["source_keywords"] = self._extract_used_keywords(
                            question, keywords
                        )
                        all_questions.append(question)

            # 5. ÌíàÏßà ÌèâÍ∞Ä
            quality_score = self.calculate_question_quality(all_questions)

            # 6. Í≤∞Í≥º Î∞òÌôò
            result = {
                "status": "success",
                "questions": all_questions,
                "metadata": {
                    "total_questions": len(all_questions),
                    "objective_count": len(
                        [q for q in all_questions if q.get("type") == "OBJECTIVE"]
                    ),
                    "subjective_count": len(
                        [q for q in all_questions if q.get("type") == "SUBJECTIVE"]
                    ),
                    "quality_score": quality_score,
                    "contexts_used": len(contexts),
                    "keywords_used": keywords,
                    "difficulty": difficulty,
                },
            }

            logger.info(
                f"‚úÖ Î∞∞Ïπò Î¨∏Ï†ú ÏÉùÏÑ± ÏôÑÎ£å: {len(all_questions)}Í∞ú, ÌíàÏßà: {quality_score:.3f}"
            )
            return result

        except Exception as e:
            logger.error(f"‚ùå Î∞∞Ïπò Î¨∏Ï†ú ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "questions": [],
                "metadata": {"contexts_count": len(contexts)},
            }

    def calculate_question_quality(self, questions: List[Dict[str, Any]]) -> float:
        """
        ÏÉùÏÑ±Îêú Î¨∏Ï†úÏùò ÌíàÏßà Ï†êÏàò Í≥ÑÏÇ∞ (LangGraph Î∂ÑÍ∏∞Ïö©)

        Args:
            questions: ÏÉùÏÑ±Îêú Î¨∏Ï†ú Î™©Î°ù

        Returns:
            float: ÌíàÏßà Ï†êÏàò (0.0-1.0)
        """
        if not questions:
            return 0.0

        total_score = 0.0
        valid_questions = 0

        for question in questions:
            question_score = 0.0

            # 1. Í∏∞Î≥∏ ÌïÑÎìú ÏôÑÏÑ±ÎèÑ (40%)
            required_fields = ["type", "question", "answer"]
            completed_fields = sum(
                1 for field in required_fields if question.get(field)
            )
            completeness_score = completed_fields / len(required_fields)

            # 2. ÌÉÄÏûÖÎ≥Ñ Ï∂îÍ∞Ä Í≤ÄÏ¶ù (30%)
            type_score = 0.0
            question_type = question.get("type", "")

            if question_type == "OBJECTIVE":
                # Í∞ùÍ¥ÄÏãù: ÏÑ†ÌÉùÏßÄÏôÄ Ï†ïÎãµÏù¥ ÏûàÏñ¥Ïïº Ìï®
                options = question.get("options", [])
                answer = question.get("answer", "")
                if options and len(options) >= 2 and answer:
                    type_score = 1.0
                elif options and answer:
                    type_score = 0.7
                elif options or answer:
                    type_score = 0.3

            elif question_type == "SUBJECTIVE":
                # Ï£ºÍ¥ÄÏãù: Î¨∏Ï†úÏôÄ ÏòàÏãú ÎãµÏïàÏù¥ ÏûàÏñ¥Ïïº Ìï®
                answer = question.get("answer", "")
                question.get("explanation", "")
                if answer and len(answer) > 10:
                    type_score = 1.0
                elif answer:
                    type_score = 0.6

            # 3. ÎÇ¥Ïö© ÌíàÏßà (30%)
            content_score = 0.0
            question_text = question.get("question", "")

            if question_text:
                # Î¨∏Ï†ú Í∏∏Ïù¥ Ï†ÅÏ†àÏÑ±
                if 10 <= len(question_text) <= 500:
                    content_score += 0.5
                elif len(question_text) > 5:
                    content_score += 0.3

                # ÌÇ§ÏõåÎìú ÏÇ¨Ïö© Ïó¨Î∂Ä
                used_keywords = question.get("source_keywords", [])
                if used_keywords:
                    content_score += 0.5
                elif question.get("keywords"):  # fallback
                    content_score += 0.3

            # Ï¢ÖÌï© Ï†êÏàò Í≥ÑÏÇ∞
            question_score = (
                completeness_score * 0.4 + type_score * 0.3 + content_score * 0.3
            )

            total_score += question_score
            valid_questions += 1

        # Ï†ÑÏ≤¥ ÌèâÍ∑† Ï†êÏàò
        average_score = total_score / valid_questions if valid_questions > 0 else 0.0
        return round(average_score, 3)
