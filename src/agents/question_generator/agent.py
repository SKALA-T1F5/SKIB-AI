"""
ë¬¸ì œ ìƒì„± Agent
- GPT-4 Visionì„ ì‚¬ìš©í•œ ìë™ ë¬¸ì œ ìƒì„±
- í…ŒìŠ¤íŠ¸ ìš”ì•½ ë° ì„¤ì • íŒŒì¼ ìƒì„±
- ë¬¸ì œ ê²°ê³¼ ì €ì¥ ë° ê´€ë¦¬
"""

import json
import os
from datetime import datetime
from typing import Dict, List

from .tools.question_generator import QuestionGenerator


class QuestionGeneratorAgent:
    """
    ë¬¸ì œ ìƒì„± ì „ë¬¸ Agent

    ì£¼ìš” ê¸°ëŠ¥:
    - GPT-4 Visionì„ ì‚¬ìš©í•œ ìë™ ë¬¸ì œ ìƒì„±
    - ê°ê´€ì‹/ì£¼ê´€ì‹ ë¬¸ì œ ìƒì„± ë° ê´€ë¦¬
    - í…ŒìŠ¤íŠ¸ ìš”ì•½ ë° ì„¤ì • íŒŒì¼ ìƒì„±
    - ë¬¸ì œ ê²°ê³¼ ì €ì¥ ë° ê´€ë¦¬
    """

    def __init__(self, collection_name: str = None):
        """
        QuestionGenerator ì´ˆê¸°í™”

        Args:
            collection_name: ì»¬ë ‰ì…˜ëª… (ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ ê²°ì •)
        """
        self.collection_name = collection_name

        # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if collection_name:
            from utils.change_name import normalize_collection_name

            normalized_name = normalize_collection_name(collection_name)
            self.image_save_dir = f"data/images/{normalized_name}"
        else:
            self.image_save_dir = "data/images/unified"

        self.question_generator = QuestionGenerator(self.image_save_dir)

    def generate_questions_from_blocks(
        self,
        blocks: List[Dict],
        num_objective: int = 3,
        num_subjective: int = 3,
        source_file: str = "document.pdf",
        keywords: List[str] = None,
        main_topics: List[str] = None,
        summary: str = "",
        test_config: Dict = None,
        use_vectordb_search: bool = True,
    ) -> Dict:
        """
        ë¸”ë¡ë“¤ë¡œë¶€í„° ë¬¸ì œ ìƒì„± (vectorDB ê²€ìƒ‰ ë° í…ŒìŠ¤íŠ¸ ì„¤ì • í™œìš©)

        Args:
            blocks: ë¬¸ì„œ ë¸”ë¡ë“¤
            num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
            num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
            source_file: ì›ë³¸ íŒŒì¼ëª…
            keywords: í‚¤ì›Œë“œ ëª©ë¡
            main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
            summary: ë¬¸ì„œ ìš”ì•½
            test_config: í…ŒìŠ¤íŠ¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬
            use_vectordb_search: vectorDBì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰ í™œìš© ì—¬ë¶€

        Returns:
            Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
        """
        print("ğŸ¤– QuestionGeneratorAgent ì‹œì‘")
        print(f"ğŸ¯ ëª©í‘œ: ê°ê´€ì‹ {num_objective}ê°œ, ì£¼ê´€ì‹ {num_subjective}ê°œ")

        try:
            # 1. VectorDBì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰ (ì„ íƒì )
            enhanced_blocks = blocks
            if use_vectordb_search and keywords and self.collection_name:
                enhanced_blocks = self._enhance_blocks_with_vectordb_search(
                    blocks, keywords, main_topics
                )

            # 2. í…ŒìŠ¤íŠ¸ ì„¤ì •ì—ì„œ ë¬¸ì œ ìˆ˜ ì¡°ì •
            if test_config:
                num_objective = test_config.get("num_objective", num_objective)
                num_subjective = test_config.get("num_subjective", num_subjective)
                print(
                    f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¤ì • ì ìš©: ê°ê´€ì‹ {num_objective}ê°œ, ì£¼ê´€ì‹ {num_subjective}ê°œ"
                )

            # 3. ë¬¸ì œ ìƒì„± (í–¥ìƒëœ ë¸”ë¡ê³¼ í…ŒìŠ¤íŠ¸ ì„¤ì • í™œìš©)
            questions_blocks = self.question_generator.generate_questions_for_blocks(
                blocks=enhanced_blocks,
                num_objective=num_objective,
                num_subjective=num_subjective,
                keywords=keywords,
                main_topics=main_topics,
                summary=summary,
                test_config=test_config,
            )

            # 2. ìƒì„±ëœ ë¬¸ì œ ì¶”ì¶œ
            all_questions = []
            for block in questions_blocks:
                if "questions" in block:
                    all_questions.extend(block["questions"])

            print(f"âœ… ì´ {len(all_questions)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")

            # 3. ê²°ê³¼ ì €ì¥
            result = self._save_question_results(
                questions=all_questions,
                source_file=source_file,
                keywords=keywords or [],
                main_topics=main_topics or [],
                summary=summary,
            )

            return result

        except Exception as e:
            print(f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "questions": [],
                "files_created": [],
            }

    def _save_question_results(
        self,
        questions: List[Dict],
        source_file: str,
        keywords: List[str],
        main_topics: List[str],
        summary: str,
    ) -> Dict:
        """
        ë¬¸ì œ ìƒì„± ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥

        Args:
            questions: ìƒì„±ëœ ë¬¸ì œ ëª©ë¡
            source_file: ì›ë³¸ íŒŒì¼ëª…
            keywords: í‚¤ì›Œë“œ ëª©ë¡
            main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
            summary: ë¬¸ì„œ ìš”ì•½

        Returns:
            Dict: ì €ì¥ ê²°ê³¼ ì •ë³´
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.splitext(os.path.basename(source_file))[0]
        files_created = []

        # 1. ìƒì„±ëœ ë¬¸ì œ íŒŒì¼ ì €ì¥
        questions_dir = "data/outputs/generated_questions"
        os.makedirs(questions_dir, exist_ok=True)

        questions_data = {
            "test_info": {
                "source_file": source_file,
                "collection_name": self.collection_name,
                "generation_date": datetime.now().isoformat(),
                "test_type": "auto_generated",
            },
            "question_summary": {
                "total_questions": len(questions),
                "objective_questions": len(
                    [q for q in questions if q.get("type") == "OBJECTIVE"]
                ),
                "subjective_questions": len(
                    [q for q in questions if q.get("type") == "SUBJECTIVE"]
                ),
                "difficulty_distribution": {
                    "easy": len(
                        [q for q in questions if q.get("difficulty_level") == "EASY"]
                    ),
                    "normal": len(
                        [q for q in questions if q.get("difficulty_level") == "NORMAL"]
                    ),
                    "hard": len(
                        [q for q in questions if q.get("difficulty_level") == "HARD"]
                    ),
                },
            },
            "questions": questions,
            "source_keywords": keywords,
            "source_topics": main_topics,
        }

        questions_file = f"{questions_dir}/{filename}_questions_{timestamp}.json"
        with open(questions_file, "w", encoding="utf-8") as f:
            json.dump(questions_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ìƒì„±ëœ ë¬¸ì œ ì €ì¥: {questions_file}")
        files_created.append(questions_file)

        # 2. í…ŒìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ìƒì„±
        summary_file = self._save_test_summary(
            questions, source_file, keywords, main_topics, summary, timestamp
        )
        if summary_file:
            files_created.append(summary_file)

        # 3. í…ŒìŠ¤íŠ¸ config íŒŒì¼ ìƒì„±
        config_file = self._save_test_config(questions, source_file, timestamp)
        if config_file:
            files_created.append(config_file)

        return {
            "status": "completed",
            "questions": questions,
            "total_questions": len(questions),
            "objective_count": len(
                [q for q in questions if q.get("type") == "OBJECTIVE"]
            ),
            "subjective_count": len(
                [q for q in questions if q.get("type") == "SUBJECTIVE"]
            ),
            "files_created": files_created,
            "collection_name": self.collection_name,
        }

    def _save_test_summary(
        self,
        questions: List[Dict],
        source_file: str,
        keywords: List[str],
        main_topics: List[str],
        summary: str,
        timestamp: str,
    ) -> str:
        """
        í…ŒìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ì €ì¥

        Args:
            questions: ìƒì„±ëœ ë¬¸ì œ ëª©ë¡
            source_file: ì›ë³¸ íŒŒì¼ëª…
            keywords: í‚¤ì›Œë“œ ëª©ë¡
            main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
            summary: ë¬¸ì„œ ìš”ì•½
            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„

        Returns:
            str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            filename = os.path.splitext(os.path.basename(source_file))[0]
            summary_dir = "data/outputs/test_summaries"
            os.makedirs(summary_dir, exist_ok=True)

            objective_questions = [q for q in questions if q.get("type") == "OBJECTIVE"]
            subjective_questions = [
                q for q in questions if q.get("type") == "SUBJECTIVE"
            ]

            test_summary_data = {
                "test_overview": {
                    "title": f"{filename} - ìë™ ìƒì„± í…ŒìŠ¤íŠ¸",
                    "description": f"'{filename}' ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ìë™ ìƒì„±í•œ í‰ê°€ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                    "source_document": source_file,
                    "creation_date": datetime.now().isoformat(),
                    "test_type": "ì¢…í•© í‰ê°€",
                    "estimated_duration": f"{max(30, len(questions) * 2)}ë¶„",
                },
                "content_analysis": {
                    "document_summary": (
                        summary[:300] + "..." if len(summary) > 300 else summary
                    ),
                    "key_concepts": keywords[:10],
                    "main_topics": main_topics[:5],
                    "content_complexity": self._analyze_content_complexity(
                        keywords, main_topics, questions
                    ),
                },
                "test_structure": {
                    "total_questions": len(questions),
                    "question_breakdown": {
                        "objective": {
                            "count": len(objective_questions),
                            "percentage": (
                                round(
                                    len(objective_questions) / len(questions) * 100, 1
                                )
                                if questions
                                else 0
                            ),
                            "focus_areas": self._extract_question_topics(
                                objective_questions
                            ),
                        },
                        "subjective": {
                            "count": len(subjective_questions),
                            "percentage": (
                                round(
                                    len(subjective_questions) / len(questions) * 100, 1
                                )
                                if questions
                                else 0
                            ),
                            "focus_areas": self._extract_question_topics(
                                subjective_questions
                            ),
                        },
                    },
                    "difficulty_distribution": {
                        "easy": len(
                            [
                                q
                                for q in questions
                                if q.get("difficulty_level") == "EASY"
                            ]
                        ),
                        "normal": len(
                            [
                                q
                                for q in questions
                                if q.get("difficulty_level") == "NORMAL"
                            ]
                        ),
                        "hard": len(
                            [
                                q
                                for q in questions
                                if q.get("difficulty_level") == "HARD"
                            ]
                        ),
                    },
                },
                "assessment_guidelines": {
                    "objective_scoring": "ê° ê°ê´€ì‹ ë¬¸í•­ë‹¹ 1ì , ì •ë‹µ/ì˜¤ë‹µìœ¼ë¡œ ì±„ì ",
                    "subjective_scoring": "ë¬¸í•­ë³„ ë°°ì ì— ë”°ë¼ ë¶€ë¶„ ì ìˆ˜ ë¶€ì—¬ ê°€ëŠ¥",
                    "total_points": len(objective_questions)
                    + len(subjective_questions) * 5,
                    "passing_criteria": "ì´ì ì˜ 60% ì´ìƒ íšë“ ì‹œ í•©ê²©",
                },
            }

            summary_file = f"{summary_dir}/{filename}_test_summary_{timestamp}.json"
            with open(summary_file, "w", encoding="utf-8") as f:
                json.dump(test_summary_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ìš”ì•½ ì €ì¥: {summary_file}")
            return summary_file

        except Exception as e:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def _save_test_config(
        self, questions: List[Dict], source_file: str, timestamp: str
    ) -> str:
        """
        í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì €ì¥

        Args:
            questions: ìƒì„±ëœ ë¬¸ì œ ëª©ë¡
            source_file: ì›ë³¸ íŒŒì¼ëª…
            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„

        Returns:
            str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            filename = os.path.splitext(os.path.basename(source_file))[0]
            config_dir = "data/outputs/test_configs"
            os.makedirs(config_dir, exist_ok=True)

            objective_questions = [q for q in questions if q.get("type") == "OBJECTIVE"]
            subjective_questions = [
                q for q in questions if q.get("type") == "SUBJECTIVE"
            ]

            test_config_data = {
                "test_metadata": {
                    "config_version": "1.0",
                    "test_id": f"auto_test_{timestamp}",
                    "source_document": source_file,
                    "generation_system": "SKIB-AI Question Generator",
                    "creation_timestamp": datetime.now().isoformat(),
                },
                "test_settings": {
                    "time_limit": {
                        "total_minutes": max(30, len(questions) * 2),
                        "warning_at_minutes": max(25, len(questions) * 2 - 5),
                        "automatic_submit": True,
                    },
                    "question_settings": {
                        "randomize_order": False,
                        "allow_review": True,
                        "show_progress": True,
                    },
                },
                "scoring_configuration": {
                    "objective_questions": {
                        "points_per_question": 1,
                        "negative_marking": False,
                    },
                    "subjective_questions": {
                        "points_per_question": 5,
                        "allow_partial_credit": True,
                        "manual_grading_required": True,
                    },
                    "total_points": len(objective_questions)
                    + len(subjective_questions) * 5,
                },
            }

            config_file = f"{config_dir}/{filename}_test_config_{timestamp}.json"
            with open(config_file, "w", encoding="utf-8") as f:
                json.dump(test_config_data, f, ensure_ascii=False, indent=2)
            print(f"âš™ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • ì €ì¥: {config_file}")
            return config_file

        except Exception as e:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def _analyze_content_complexity(
        self, keywords: List[str], main_topics: List[str], questions: List[Dict]
    ) -> str:
        """
        ì½˜í…ì¸  ë³µì¡ë„ ë¶„ì„

        Args:
            keywords: í‚¤ì›Œë“œ ëª©ë¡
            main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
            questions: ìƒì„±ëœ ë¬¸ì œ ëª©ë¡

        Returns:
            str: ë³µì¡ë„ ë“±ê¸‰ ("ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰")
        """
        keywords_count = len(keywords)
        topics_count = len(main_topics)
        hard_questions = len(
            [q for q in questions if q.get("difficulty_level") == "HARD"]
        )

        if keywords_count > 10 and topics_count > 5 and hard_questions > 2:
            return "ê³ ê¸‰"
        elif keywords_count > 5 and topics_count > 3:
            return "ì¤‘ê¸‰"
        else:
            return "ì´ˆê¸‰"

    def _extract_question_topics(self, questions: List[Dict]) -> List[str]:
        """
        ë¬¸ì œì—ì„œ ì£¼ìš” ì£¼ì œ ì¶”ì¶œ

        Args:
            questions: ë¬¸ì œ ëª©ë¡

        Returns:
            List[str]: ì¶”ì¶œëœ ì£¼ì œ ëª©ë¡ (ìµœëŒ€ 3ê°œ)
        """
        topics = []
        for q in questions[:3]:  # ìƒìœ„ 3ê°œ ë¬¸ì œë§Œ ë¶„ì„
            question_text = q.get("question", "")
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            if "í”„ë¡œì„¸ìŠ¤" in question_text:
                topics.append("í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬")
            if "ì—…ë¬´" in question_text:
                topics.append("ì—…ë¬´ ì²˜ë¦¬")
            if "ê³„ì•½" in question_text:
                topics.append("ê³„ì•½ ê´€ë¦¬")
            if "ë“±ë¡" in question_text:
                topics.append("ë“±ë¡ ì ˆì°¨")

        return list(set(topics))[:3]  # ì¤‘ë³µ ì œê±° í›„ ìƒìœ„ 3ê°œ ë°˜í™˜

    def _enhance_blocks_with_vectordb_search(
        self, blocks: List[Dict], keywords: List[str], main_topics: List[str]
    ) -> List[Dict]:
        """
        VectorDB ê²€ìƒ‰ì„ í†µí•´ ë¸”ë¡ì„ í–¥ìƒì‹œí‚¤ëŠ” ë©”ì„œë“œ

        Args:
            blocks: ì›ë³¸ ë¸”ë¡ë“¤
            keywords: ê²€ìƒ‰í•  í‚¤ì›Œë“œë“¤
            main_topics: ì£¼ìš” ì£¼ì œë“¤

        Returns:
            List[Dict]: í–¥ìƒëœ ë¸”ë¡ë“¤ (ê´€ë ¨ ë‚´ìš© ì¶”ê°€)
        """
        try:
            print("ğŸ” VectorDBì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘...")

            # ChromaDB ê²€ìƒ‰ ì‹œë„
            try:
                from db.vectorDB.chromaDB.search import search_documents

                enhanced_blocks = blocks.copy()
                related_contents = []

                # ìƒìœ„ í‚¤ì›Œë“œë“¤ë¡œ ê²€ìƒ‰
                top_keywords = keywords[:5]  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
                for keyword in top_keywords:
                    try:
                        search_results = search_documents(
                            query=keyword,
                            collection_name=self.collection_name,
                            n_results=3,
                        )

                        if search_results and "documents" in search_results:
                            for doc in search_results["documents"][
                                0
                            ]:  # ì²« ë²ˆì§¸ ê²€ìƒ‰ ê²°ê³¼ ë°°ì¹˜
                                if doc not in related_contents:
                                    related_contents.append(doc)

                    except Exception as e:
                        print(f"  âš ï¸ í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                        continue

                # ê²€ìƒ‰ëœ ê´€ë ¨ ë‚´ìš©ì„ ë¸”ë¡ì— ì¶”ê°€
                if related_contents:
                    print(f"  âœ… {len(related_contents)}ê°œ ê´€ë ¨ ë‚´ìš© ë°œê²¬")

                    # ê´€ë ¨ ë‚´ìš©ì„ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ ë¸”ë¡ìœ¼ë¡œ ì¶”ê°€
                    for i, content in enumerate(
                        related_contents[:3]
                    ):  # ìµœëŒ€ 3ê°œë§Œ ì¶”ê°€
                        related_block = {
                            "type": "paragraph",
                            "content": f"[ê´€ë ¨ ë‚´ìš© {i+1}] {content}",
                            "metadata": {
                                "source": "vectordb_search",
                                "search_keyword": (
                                    keywords[i % len(keywords)]
                                    if keywords
                                    else "unknown"
                                ),
                                "page": "vectordb",
                            },
                        }
                        enhanced_blocks.append(related_block)

                return enhanced_blocks

            except ImportError:
                print("  âš ï¸ ChromaDB ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ë¸”ë¡ ì‚¬ìš©")
                return blocks

        except Exception as e:
            print(f"  âŒ VectorDB ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return blocks


# í¸ì˜ í•¨ìˆ˜
def generate_questions_from_document(
    blocks: List[Dict],
    collection_name: str = None,
    num_objective: int = 3,
    num_subjective: int = 3,
    source_file: str = "document.pdf",
    keywords: List[str] = None,
    main_topics: List[str] = None,
    summary: str = "",
) -> Dict:
    """
    ë¬¸ì„œ ë¸”ë¡ë“¤ë¡œë¶€í„° ë¬¸ì œ ìƒì„± í¸ì˜ í•¨ìˆ˜

    Args:
        blocks: ë¬¸ì„œ ë¸”ë¡ë“¤
        collection_name: ì»¬ë ‰ì…˜ëª…
        num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
        num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
        source_file: ì›ë³¸ íŒŒì¼ëª…
        keywords: í‚¤ì›Œë“œ ëª©ë¡
        main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
        summary: ë¬¸ì„œ ìš”ì•½

    Returns:
        Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
    """
    agent = QuestionGeneratorAgent(collection_name)
    return agent.generate_questions_from_blocks(
        blocks,
        num_objective,
        num_subjective,
        source_file,
        keywords,
        main_topics,
        summary,
    )


"""
ë¬¸ì œ ìƒì„± Agent
- GPT-4 Visionì„ ì‚¬ìš©í•œ ìë™ ë¬¸ì œ ìƒì„±
- í…ŒìŠ¤íŠ¸ ìš”ì•½ ë° ì„¤ì • íŒŒì¼ ìƒì„±
- ë¬¸ì œ ê²°ê³¼ ì €ì¥ ë° ê´€ë¦¬
"""

import json
import os
from datetime import datetime
from typing import Dict, List

from .tools.question_generator import QuestionGenerator


class QuestionGeneratorAgent:
    """ë¬¸ì œ ìƒì„± ì „ë¬¸ Agent"""

    def __init__(self, collection_name: str = None):
        self.collection_name = collection_name
        # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if collection_name:
            from utils.naming import filename_to_collection

            normalized_name = filename_to_collection(collection_name)
            self.image_save_dir = f"data/images/{normalized_name}"
        else:
            self.image_save_dir = "data/images/unified"
        self.question_generator = QuestionGenerator(self.image_save_dir)

    def generate_questions_from_blocks(
        self,
        blocks: List[Dict],
        num_objective: int = 3,
        num_subjective: int = 3,
        source_file: str = "document.pdf",
        keywords: List[str] = None,
        main_topics: List[str] = None,
        summary: str = "",
    ) -> Dict:
        """
        ë¸”ë¡ë“¤ë¡œë¶€í„° ë¬¸ì œ ìƒì„±

        Args:
            blocks: ë¬¸ì„œ ë¸”ë¡ë“¤
            num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
            num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
            source_file: ì›ë³¸ íŒŒì¼ëª…
            keywords: í‚¤ì›Œë“œ ëª©ë¡
            main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
            summary: ë¬¸ì„œ ìš”ì•½

        Returns:
            Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
        """
        print("ğŸ¤– QuestionGeneratorAgent ì‹œì‘")
        print(f"ğŸ¯ ëª©í‘œ: ê°ê´€ì‹ {num_objective}ê°œ, ì£¼ê´€ì‹ {num_subjective}ê°œ")

        try:
            # 1. ë¬¸ì œ ìƒì„±
            questions_blocks = self.question_generator.generate_questions_for_blocks(
                blocks, num_objective, num_subjective
            )

            # 2. ìƒì„±ëœ ë¬¸ì œ ì¶”ì¶œ
            all_questions = []
            for block in questions_blocks:
                if "questions" in block:
                    all_questions.extend(block["questions"])

            print(f"âœ… ì´ {len(all_questions)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")

            # 3. ê²°ê³¼ ì €ì¥
            result = self._save_question_results(
                questions=all_questions,
                source_file=source_file,
                keywords=keywords or [],
                main_topics=main_topics or [],
                summary=summary,
            )

            return result

        except Exception as e:
            print(f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "questions": [],
                "files_created": [],
            }

    def _save_question_results(
        self,
        questions: List[Dict],
        source_file: str,
        keywords: List[str],
        main_topics: List[str],
        summary: str,
    ) -> Dict:
        """ë¬¸ì œ ìƒì„± ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.splitext(os.path.basename(source_file))[0]
        files_created = []

        # 1. ìƒì„±ëœ ë¬¸ì œ íŒŒì¼ ì €ì¥
        questions_dir = "data/outputs/generated_questions"
        os.makedirs(questions_dir, exist_ok=True)

        questions_data = {
            "test_info": {
                "source_file": source_file,
                "collection_name": self.collection_name,
                "generation_date": datetime.now().isoformat(),
                "test_type": "auto_generated",
            },
            "question_summary": {
                "total_questions": len(questions),
                "objective_questions": len(
                    [q for q in questions if q.get("type") == "OBJECTIVE"]
                ),
                "subjective_questions": len(
                    [q for q in questions if q.get("type") == "SUBJECTIVE"]
                ),
                "difficulty_distribution": {
                    "easy": len(
                        [q for q in questions if q.get("difficulty_level") == "EASY"]
                    ),
                    "normal": len(
                        [q for q in questions if q.get("difficulty_level") == "NORMAL"]
                    ),
                    "hard": len(
                        [q for q in questions if q.get("difficulty_level") == "HARD"]
                    ),
                },
            },
            "questions": questions,
            "source_keywords": keywords,
            "source_topics": main_topics,
        }

        questions_file = f"{questions_dir}/{filename}_questions_{timestamp}.json"
        with open(questions_file, "w", encoding="utf-8") as f:
            json.dump(questions_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ìƒì„±ëœ ë¬¸ì œ ì €ì¥: {questions_file}")
        files_created.append(questions_file)

        # 2. í…ŒìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ìƒì„±
        summary_file = self._save_test_summary(
            questions, source_file, keywords, main_topics, summary, timestamp
        )
        if summary_file:
            files_created.append(summary_file)

        # 3. í…ŒìŠ¤íŠ¸ config íŒŒì¼ ìƒì„±
        config_file = self._save_test_config(questions, source_file, timestamp)
        if config_file:
            files_created.append(config_file)

        return {
            "status": "completed",
            "questions": questions,
            "total_questions": len(questions),
            "objective_count": len(
                [q for q in questions if q.get("type") == "OBJECTIVE"]
            ),
            "subjective_count": len(
                [q for q in questions if q.get("type") == "SUBJECTIVE"]
            ),
            "files_created": files_created,
            "collection_name": self.collection_name,
        }

    def _save_test_summary(
        self,
        questions: List[Dict],
        source_file: str,
        keywords: List[str],
        main_topics: List[str],
        summary: str,
        timestamp: str,
    ) -> str:
        """í…ŒìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ì €ì¥"""
        try:
            filename = os.path.splitext(os.path.basename(source_file))[0]
            summary_dir = "data/outputs/test_summaries"
            os.makedirs(summary_dir, exist_ok=True)

            objective_questions = [q for q in questions if q.get("type") == "OBJECTIVE"]
            subjective_questions = [
                q for q in questions if q.get("type") == "SUBJECTIVE"
            ]

            test_summary_data = {
                "test_overview": {
                    "title": f"{filename} - ìë™ ìƒì„± í…ŒìŠ¤íŠ¸",
                    "description": f"'{filename}' ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ìë™ ìƒì„±í•œ í‰ê°€ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                    "source_document": source_file,
                    "creation_date": datetime.now().isoformat(),
                    "test_type": "ì¢…í•© í‰ê°€",
                    "estimated_duration": f"{max(30, len(questions) * 2)}ë¶„",
                },
                "content_analysis": {
                    "document_summary": (
                        summary[:300] + "..." if len(summary) > 300 else summary
                    ),
                    "key_concepts": keywords[:10],
                    "main_topics": main_topics[:5],
                    "content_complexity": self._analyze_content_complexity(
                        keywords, main_topics, questions
                    ),
                },
                "test_structure": {
                    "total_questions": len(questions),
                    "question_breakdown": {
                        "objective": {
                            "count": len(objective_questions),
                            "percentage": (
                                round(
                                    len(objective_questions) / len(questions) * 100, 1
                                )
                                if questions
                                else 0
                            ),
                            "focus_areas": self._extract_question_topics(
                                objective_questions
                            ),
                        },
                        "subjective": {
                            "count": len(subjective_questions),
                            "percentage": (
                                round(
                                    len(subjective_questions) / len(questions) * 100, 1
                                )
                                if questions
                                else 0
                            ),
                            "focus_areas": self._extract_question_topics(
                                subjective_questions
                            ),
                        },
                    },
                    "difficulty_distribution": {
                        "easy": len(
                            [
                                q
                                for q in questions
                                if q.get("difficulty_level") == "EASY"
                            ]
                        ),
                        "normal": len(
                            [
                                q
                                for q in questions
                                if q.get("difficulty_level") == "NORMAL"
                            ]
                        ),
                        "hard": len(
                            [
                                q
                                for q in questions
                                if q.get("difficulty_level") == "HARD"
                            ]
                        ),
                    },
                },
                "assessment_guidelines": {
                    "objective_scoring": "ê° ê°ê´€ì‹ ë¬¸í•­ë‹¹ 1ì , ì •ë‹µ/ì˜¤ë‹µìœ¼ë¡œ ì±„ì ",
                    "subjective_scoring": "ë¬¸í•­ë³„ ë°°ì ì— ë”°ë¼ ë¶€ë¶„ ì ìˆ˜ ë¶€ì—¬ ê°€ëŠ¥",
                    "total_points": len(objective_questions)
                    + len(subjective_questions) * 5,
                    "passing_criteria": "ì´ì ì˜ 60% ì´ìƒ íšë“ ì‹œ í•©ê²©",
                },
            }

            summary_file = f"{summary_dir}/{filename}_test_summary_{timestamp}.json"
            with open(summary_file, "w", encoding="utf-8") as f:
                json.dump(test_summary_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ìš”ì•½ ì €ì¥: {summary_file}")
            return summary_file

        except Exception as e:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def _save_test_config(
        self, questions: List[Dict], source_file: str, timestamp: str
    ) -> str:
        """í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            filename = os.path.splitext(os.path.basename(source_file))[0]
            config_dir = "data/outputs/test_configs"
            os.makedirs(config_dir, exist_ok=True)

            objective_questions = [q for q in questions if q.get("type") == "OBJECTIVE"]
            subjective_questions = [
                q for q in questions if q.get("type") == "SUBJECTIVE"
            ]

            test_config_data = {
                "test_metadata": {
                    "config_version": "1.0",
                    "test_id": f"auto_test_{timestamp}",
                    "source_document": source_file,
                    "generation_system": "SKIB-AI Question Generator",
                    "creation_timestamp": datetime.now().isoformat(),
                },
                "test_settings": {
                    "time_limit": {
                        "total_minutes": max(30, len(questions) * 2),
                        "warning_at_minutes": max(25, len(questions) * 2 - 5),
                        "automatic_submit": True,
                    },
                    "question_settings": {
                        "randomize_order": False,
                        "allow_review": True,
                        "show_progress": True,
                    },
                },
                "scoring_configuration": {
                    "objective_questions": {
                        "points_per_question": 1,
                        "negative_marking": False,
                    },
                    "subjective_questions": {
                        "points_per_question": 5,
                        "allow_partial_credit": True,
                        "manual_grading_required": True,
                    },
                    "total_points": len(objective_questions)
                    + len(subjective_questions) * 5,
                },
            }

            config_file = f"{config_dir}/{filename}_test_config_{timestamp}.json"
            with open(config_file, "w", encoding="utf-8") as f:
                json.dump(test_config_data, f, ensure_ascii=False, indent=2)
            print(f"âš™ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • ì €ì¥: {config_file}")
            return config_file

        except Exception as e:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def _analyze_content_complexity(
        self, keywords: List[str], main_topics: List[str], questions: List[Dict]
    ) -> str:
        """ì½˜í…ì¸  ë³µì¡ë„ ë¶„ì„"""
        keywords_count = len(keywords)
        topics_count = len(main_topics)
        hard_questions = len(
            [q for q in questions if q.get("difficulty_level") == "HARD"]
        )

        if keywords_count > 10 and topics_count > 5 and hard_questions > 2:
            return "ê³ ê¸‰"
        elif keywords_count > 5 and topics_count > 3:
            return "ì¤‘ê¸‰"
        else:
            return "ì´ˆê¸‰"

    def _extract_question_topics(self, questions: List[Dict]) -> List[str]:
        """ë¬¸ì œì—ì„œ ì£¼ìš” ì£¼ì œ ì¶”ì¶œ"""
        topics = []
        for q in questions[:3]:  # ìƒìœ„ 3ê°œ ë¬¸ì œë§Œ ë¶„ì„
            question_text = q.get("question", "")
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            if "í”„ë¡œì„¸ìŠ¤" in question_text:
                topics.append("í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬")
            if "ì—…ë¬´" in question_text:
                topics.append("ì—…ë¬´ ì²˜ë¦¬")
            if "ê³„ì•½" in question_text:
                topics.append("ê³„ì•½ ê´€ë¦¬")
            if "ë“±ë¡" in question_text:
                topics.append("ë“±ë¡ ì ˆì°¨")

        return list(set(topics))[:3]  # ì¤‘ë³µ ì œê±° í›„ ìƒìœ„ 3ê°œ ë°˜í™˜


# í¸ì˜ í•¨ìˆ˜
def generate_questions_from_document(
    blocks: List[Dict],
    collection_name: str = None,
    num_objective: int = 3,
    num_subjective: int = 3,
    source_file: str = "document.pdf",
    keywords: List[str] = None,
    main_topics: List[str] = None,
    summary: str = "",
) -> Dict:
    """
    ë¬¸ì„œ ë¸”ë¡ë“¤ë¡œë¶€í„° ë¬¸ì œ ìƒì„± í¸ì˜ í•¨ìˆ˜

    Args:
        blocks: ë¬¸ì„œ ë¸”ë¡ë“¤
        collection_name: ì»¬ë ‰ì…˜ëª…
        num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
        num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
        source_file: ì›ë³¸ íŒŒì¼ëª…
        keywords: í‚¤ì›Œë“œ ëª©ë¡
        main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
        summary: ë¬¸ì„œ ìš”ì•½

    Returns:
        Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
    """
    agent = QuestionGeneratorAgent(collection_name)
    return agent.generate_questions_from_blocks(
        blocks,
        num_objective,
        num_subjective,
        source_file,
        keywords,
        main_topics,
        summary,
    )
