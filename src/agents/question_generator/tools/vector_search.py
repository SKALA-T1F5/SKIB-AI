"""
VectorDB ê²€ìƒ‰ ê´€ë ¨ ë„êµ¬
"""

from typing import Dict, List, Any


class VectorSearchHandler:
    """VectorDB ê²€ìƒ‰ ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.searcher = None
        try:
            from db.vectorDB.chromaDB.search import ChromaDBSearcher
            self.searcher = ChromaDBSearcher()
            print("ğŸ” VectorDB ê²€ìƒ‰ í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
        except ImportError:
            print("âš ï¸ VectorDB ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def _convert_document_name_to_collection(self, document_name: str) -> str:
        """ë¬¸ì„œëª…ì„ collectionëª…ìœ¼ë¡œ ë³€í™˜"""
        if not document_name:
            return "unified_collection"
        
        # ì´ë¯¸ ì ì ˆí•œ collectionëª…ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if document_name.startswith(('doc_', 'c_')) and '_' in document_name:
            return document_name
        
        # ìš°ì„  ì›ë³¸ ì´ë¦„ ê·¸ëŒ€ë¡œ ì‹œë„ (doc_ ì ‘ë‘ì‚¬ ì—†ì´)
        original_name = document_name
        
        # ChromaDBì—ì„œ ì‹¤ì œ ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        try:
            if self.searcher and hasattr(self.searcher, 'client'):
                collections = self.searcher.client.list_collections()
                collection_names = [c.name for c in collections]
                
                # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì»¬ë ‰ì…˜ ì°¾ê¸°
                if original_name in collection_names:
                    print(f"ğŸ“ ë¬¸ì„œëª… ë³€í™˜: '{document_name}' â†’ '{original_name}' (ì •í™• ì¼ì¹˜)")
                    return original_name
                
                # doc_ ì ‘ë‘ì‚¬ê°€ ìˆëŠ” ë²„ì „ í™•ì¸
                doc_prefixed = f"doc_{original_name}"
                if doc_prefixed in collection_names:
                    print(f"ğŸ“ ë¬¸ì„œëª… ë³€í™˜: '{document_name}' â†’ '{doc_prefixed}' (doc_ ì ‘ë‘ì‚¬)")
                    return doc_prefixed
                
                # ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
                partial_matches = [name for name in collection_names if original_name in name or name in original_name]
                if partial_matches:
                    best_match = partial_matches[0]
                    print(f"ğŸ“ ë¬¸ì„œëª… ë³€í™˜: '{document_name}' â†’ '{best_match}' (ë¶€ë¶„ ì¼ì¹˜)")
                    return best_match
                    
        except Exception as e:
            print(f"âš ï¸ ì»¬ë ‰ì…˜ ëª©ë¡ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        # Fallback: ë¬¸ì„œëª… ë³€í™˜ ë¡œì§
        import re
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
        clean_name = re.sub(r'[^a-zA-Z0-9ê°€-í£_]', '_', document_name.lower())
        
        # ì—°ì†ëœ ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
        clean_name = re.sub(r'_+', '_', clean_name)
        
        # ì•ë’¤ ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
        clean_name = clean_name.strip('_')
        
        # ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ê¸°ë³¸ê°’
        if not clean_name:
            return "unified_collection"
        
        print(f"ğŸ“ ë¬¸ì„œëª… ë³€í™˜: '{document_name}' â†’ '{clean_name}' (fallback)")
        return clean_name
    
    def search_keywords_in_collection(
        self, 
        keywords: List[str], 
        document_name: str, 
        max_results_per_keyword: int = 3
    ) -> List[Dict]:
        """ë¬¸ì„œëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì»¬ë ‰ì…˜ì—ì„œ í‚¤ì›Œë“œ ê´€ë ¨ ì½˜í…ì¸  ê²€ìƒ‰"""
        if not self.searcher:
            print("âš ï¸ VectorDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        # ë¬¸ì„œëª…ì„ collectionëª…ìœ¼ë¡œ ë³€í™˜
        collection_name = self._convert_document_name_to_collection(document_name)
        
        all_content = []
        
        for keyword in keywords[:5]:  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
            print(f"ğŸ” í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì¤‘...")
            
            try:
                # í‚¤ì›Œë“œë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰
                results = self.searcher.search_similar(
                    query=keyword,
                    collection_name=collection_name,
                    n_results=max_results_per_keyword,
                    where=None
                )
                
                if results:
                    print(f"  âœ… ì»¬ë ‰ì…˜ '{collection_name}'ì—ì„œ {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
                    for result in results:
                        result['search_keyword'] = keyword
                        result['source_collection'] = collection_name
                        result['original_document_name'] = document_name
                    all_content.extend(results)
                else:
                    print(f"  âŒ í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            except Exception as e:
                print(f"  âš ï¸ í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° fallback ì‹œë„
        if not all_content:
            print(f"âš ï¸ VectorDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì»¬ë ‰ì…˜ '{collection_name}'ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ. Fallback ì»¬ë ‰ì…˜ì—ì„œ ì¬ì‹œë„...")
            fallback_results = self.search_with_fallback_collections(
                keywords=keywords,
                primary_document_name=None  # ì´ë¯¸ ì‹¤íŒ¨í–ˆìœ¼ë¯€ë¡œ None
            )
            if fallback_results:
                print(f"âœ… Fallback ê²€ìƒ‰ìœ¼ë¡œ {len(fallback_results)}ê°œ ì½˜í…ì¸  ë°œê²¬")
                all_content.extend(fallback_results)
            else:
                print("âš ï¸ VectorDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ“Š ì´ {len(all_content)}ê°œ ê´€ë ¨ ì½˜í…ì¸  ë°œê²¬")
        return all_content
    
    def search_with_fallback_collections(
        self, 
        keywords: List[str], 
        primary_document_name: str = None,
        fallback_collections: List[str] = None
    ) -> List[Dict]:
        """ì£¼ ë¬¸ì„œì—ì„œ ê²€ìƒ‰ í›„ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰"""
        if not fallback_collections:
            fallback_collections = [
                "document_chunks",
                "unified_collection", 
                "skib_documents",
                "doc_2_ags_trouble_shooting_v1_1",
                "to_be_portal_process_fp_07_v1_0"
            ]
        
        # ì£¼ ë¬¸ì„œëª…ì´ ì§€ì •ëœ ê²½ìš° ë¨¼ì € ì‹œë„
        if primary_document_name:
            content = self.search_keywords_in_collection(keywords, primary_document_name)
            if content:
                return content
        
        # ëŒ€ì²´ ì»¬ë ‰ì…˜ë“¤ì—ì„œ ì§ì ‘ ê²€ìƒ‰ (ì´ë¯¸ collectionëª…ì¸ ê²½ìš°)
        primary_collection = self._convert_document_name_to_collection(primary_document_name) if primary_document_name else None
        
        for collection in fallback_collections:
            if collection == primary_collection:
                continue  # ì´ë¯¸ ì‹œë„í•œ ì»¬ë ‰ì…˜ì€ ìŠ¤í‚µ
            
            try:
                # ëŒ€ì²´ ì»¬ë ‰ì…˜ì—ì„œ ì§ì ‘ ê²€ìƒ‰
                content = self._search_in_specific_collection(keywords, collection)
                if content:
                    return content
            except Exception as e:
                print(f"  âš ï¸ ì»¬ë ‰ì…˜ '{collection}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue
        
        return []
    
    def _search_in_specific_collection(self, keywords: List[str], collection_name: str, max_results_per_keyword: int = 3) -> List[Dict]:
        """íŠ¹ì • ì»¬ë ‰ì…˜ì—ì„œ ì§ì ‘ ê²€ìƒ‰ (ë³€í™˜ ì—†ì´)"""
        if not self.searcher:
            print("âš ï¸ VectorDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ê¸°ê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        all_content = []
        
        for keyword in keywords[:5]:
            try:
                results = self.searcher.search_similar(
                    query=keyword,
                    collection_name=collection_name,
                    n_results=max_results_per_keyword,
                    where=None
                )
                
                if results:
                    print(f"  âœ… ëŒ€ì²´ ì»¬ë ‰ì…˜ '{collection_name}'ì—ì„œ {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
                    for result in results:
                        result['search_keyword'] = keyword
                        result['source_collection'] = collection_name
                        result['is_fallback'] = True
                    all_content.extend(results)
            except Exception as e:
                print(f"  âš ï¸ í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue
        
        return all_content
    
    def convert_content_to_blocks(self, related_content: List[Dict], keywords: List[str]) -> List[Dict]:
        """ê´€ë ¨ ì½˜í…ì¸ ë¥¼ ë¸”ë¡ í˜•íƒœë¡œ ë³€í™˜"""
        blocks = []
        
        # í‚¤ì›Œë“œ ì •ë³´ë¥¼ í¬í•¨í•œ í—¤ë” ë¸”ë¡ ì¶”ê°€
        header_content = f"ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(keywords)}\n\n"
        blocks.append({
            "type": "heading",
            "content": header_content,
            "metadata": {"page": 1, "source": "keyword_context"}
        })
        
        # ê´€ë ¨ ì½˜í…ì¸ ë¥¼ ë¸”ë¡ìœ¼ë¡œ ë³€í™˜
        for i, content in enumerate(related_content[:10]):  # ìƒìœ„ 10ê°œë§Œ ì‚¬ìš©
            block = {
                "type": "paragraph",
                "content": content.get('content', ''),
                "metadata": {
                    "page": i + 1,
                    "source": content.get('source_collection', 'vector_search'),
                    "search_keyword": content.get('search_keyword', ''),
                    "similarity": content.get('similarity', 0.0)
                }
            }
            blocks.append(block)
        
        return blocks