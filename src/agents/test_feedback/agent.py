# agents/test_feedback/agent.py
import os
import openai
import json

from openai import AsyncOpenAI
from typing import List, Dict, Any
from api.grading.schemas.subjective_grading import GradingCriterion
from utils.parse_json_response import parse_json_response

from dotenv import load_dotenv
from src.agents.test_feedback.prompt import SYSTEM_PROMPT, build_user_prompt


#openai ë¡œë“œ
load_dotenv(override=True) 
api_key = os.getenv("OPENAI_API_KEY") 
openai_client = AsyncOpenAI(api_key=api_key) 
AGENT_MODEL = os.getenv("AGENT_TEST_FEEDBACK_MODEL") #.envì— ëª¨ë¸ëª… ì €ì¥ (AGENT_TEST_FEEDBACK_MODEL=gpt-4)âœ…

async def test_feedback(exam_goal: str, question_results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    OpenAIë¥¼ ì´ìš©í•˜ì—¬ ì‹œí—˜ëª©í‘œì™€ ë¬¸í•­ë³„ ì‘ì‹œ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¢…í•©ì ì¸ í”¼ë“œë°±ì„ ë°˜í™˜
    """
    # 1. ì±„ì  ê¸°ì¤€ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì„ íƒì‚¬í•­)
    # criteria_prompt = ""
    # if grading_criteria:
    #     criteria_prompt = "\n".join([
    #         f"{c.score} | {c.criteria} | ex: {c.example}" for c in grading_criteria
    #     ])

    # 2. ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    USER_PROMPT = build_user_prompt(exam_goal, question_results)

    # 3. MODEL í˜¸ì¶œ
    try:
        # RAW INPUT ì¶œë ¥ #########################################
        print("\n" + "="*80)
        print("ğŸ¤– MODEL INPUT (RAW)")
        print("="*80)
        print("ğŸ“‹ SYSTEM PROMPT:")
        print(SYSTEM_PROMPT)
        print("\nğŸ“ USER PROMPT:")
        print(USER_PROMPT)
        print("="*80)
        ########################################################
        
        response = await openai_client.chat.completions.create(
            model=AGENT_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": USER_PROMPT}
            ],
            temperature=0.2,
        )

        content = response.choices[0].message.content.strip()
        
        # RAW OUTPUT ì¶œë ¥ #########################################
        print("\n" + "="*80)
        print("ğŸ¤– MODEL OUTPUT (RAW)")
        print("="*80)
        print(content)
        print("="*80)
        ########################################################

        result = json.loads(content)

        # í† í° ì‚¬ìš©ëŸ‰ (ì°¨í›„ ì£¼ì„ì²˜ë¦¬ âœ… )
        usage = response.usage
        print("ğŸŸ¨ ì‚¬ìš© í† í°:", usage.total_tokens)
        print("â””â”€ prompt_tokens:", usage.prompt_tokens)
        print("â””â”€ completion_tokens:", usage.completion_tokens)
        
        return result

    except Exception as e:
        raise RuntimeError(f"ì‹œí—˜ í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {str(e)}")