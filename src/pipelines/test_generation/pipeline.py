"""
í…ŒìŠ¤íŠ¸ ìƒì„± Pipeline
ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•˜ëŠ” ë©”ì¸ íŒŒì´í”„ë¼ì¸

ì›Œí¬í”Œë¡œìš°:
1. ë¬¸ì„œ ë¶„ì„ Agent -> íŒŒì‹± -> VectorDB ì—…ë¡œë“œ + í‚¤ì›Œë“œ/ìš”ì•½ ìƒì„±
2. í…ŒìŠ¤íŠ¸ ì„¤ê³„ Agent -> GPT-4ë¡œ í…ŒìŠ¤íŠ¸ ìš”ì•½ + config ìƒì„±
3. ì§ˆë¬¸ ìƒì„± Agent -> GPT-4o Visionìœ¼ë¡œ ë¬¸ì œ ìƒì„±
"""

import os
import json
import time
from typing import Dict, Any, List
from sentence_transformers import SentenceTransformer

from src.agents.document_analyzer.agent import DocumentAnalyzerAgent
from src.agents.test_designer.agent import TestDesignerAgent
from src.agents.question_generator.tools.question_generator import QuestionGenerator
from db.vectorDB.weaviate_utils import upload_chunk_to_collection
from utils.change_name import normalize_collection_name


class TestGenerationPipeline:
    """í…ŒìŠ¤íŠ¸ ìƒì„± ì „ì²´ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.embedding_model = SentenceTransformer("BAAI/bge-base-en")
        self.document_analyzer = None
        self.test_designer = None
        
    async def initialize(self):
        """íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.document_analyzer = DocumentAnalyzerAgent()
        self.test_designer = TestDesignerAgent()
        await self.test_designer.initialize()
    
    async def run_complete_workflow(
        self,
        pdf_path: str,
        user_prompt: str,
        collection_name: str = None,
        difficulty: str = "medium",
        upload_to_vectordb: bool = True
    ) -> Dict[str, Any]:
        """
        ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            user_prompt: ì‚¬ìš©ì ìš”ì²­ í”„ë¡¬í”„íŠ¸
            collection_name: ì»¬ë ‰ì…˜ëª…
            difficulty: ë‚œì´ë„
            upload_to_vectordb: VectorDB ì—…ë¡œë“œ ì—¬ë¶€
            
        Returns:
            ì „ì²´ ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.document_analyzer or not self.test_designer:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            # ì»¬ë ‰ì…˜ëª… ì„¤ì •
            if not collection_name:
                filename = os.path.splitext(os.path.basename(pdf_path))[0]
                collection_name = normalize_collection_name(filename)
            
            print(f"ğŸš€ í…ŒìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            print(f"ğŸ“ ì»¬ë ‰ì…˜: {collection_name}")
            print(f"ğŸ“„ ë¬¸ì„œ: {pdf_path}")
            print(f"ğŸ’­ ì‚¬ìš©ì ìš”ì²­: {user_prompt}")
            print("=" * 80)
            
            # 1ë‹¨ê³„: ë¬¸ì„œ ë¶„ì„
            print("\n1ï¸âƒ£ ë¬¸ì„œ ë¶„ì„ ë° ì²˜ë¦¬")
            doc_result = await self._step1_document_analysis(
                pdf_path, collection_name, upload_to_vectordb
            )
            
            # 2ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì„¤ê³„
            print("\n2ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì„¤ê³„")
            design_result = await self._step2_test_design(
                doc_result, user_prompt, difficulty
            )
            
            # 3ë‹¨ê³„: ë¬¸ì œ ìƒì„±
            print("\n3ï¸âƒ£ ë¬¸ì œ ìƒì„±")
            questions_result = await self._step3_question_generation(
                doc_result, design_result
            )
            
            # ê²°ê³¼ ì¢…í•©
            total_time = time.time() - start_time
            
            final_result = {
                "pipeline_info": {
                    "collection_name": collection_name,
                    "pdf_path": pdf_path,
                    "user_prompt": user_prompt,
                    "difficulty": difficulty,
                    "processing_time": round(total_time, 2),
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                },
                "document_analysis": doc_result,
                "test_design": design_result,
                "questions": questions_result,
                "status": "completed"
            }
            
            # ê²°ê³¼ ì €ì¥
            await self._save_results(final_result, collection_name)
            
            print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ!")
            print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"ğŸ“Š ìƒì„±ëœ ë¬¸ì œ ìˆ˜: {len(questions_result.get('questions', []))}ê°œ")
            
            return final_result
            
        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
    
    async def _step1_document_analysis(
        self, 
        pdf_path: str, 
        collection_name: str, 
        upload_to_vectordb: bool
    ) -> Dict[str, Any]:
        """1ë‹¨ê³„: ë¬¸ì„œ ë¶„ì„ ë° VectorDB ì—…ë¡œë“œ"""
        
        # ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰
        print("  ğŸ“„ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì¤‘...")
        self.document_analyzer = DocumentAnalyzerAgent(collection_name)
        doc_state = self.document_analyzer.analyze_document(
            pdf_path, 
            extract_keywords=True
        )
        
        if doc_state.get("processing_status") != "completed":
            raise Exception(f"ë¬¸ì„œ ë¶„ì„ ì‹¤íŒ¨: {doc_state.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        print(f"  âœ… ë¶„ì„ ì™„ë£Œ: {doc_state.get('total_blocks', 0)}ê°œ ë¸”ë¡")
        
        # VectorDB ì—…ë¡œë“œ
        if upload_to_vectordb:
            print("  ğŸ“¤ VectorDB ì—…ë¡œë“œ ì¤‘...")
            uploaded_count = await self._upload_to_vectordb(doc_state.get("blocks", []), collection_name)
            print(f"  âœ… ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_count}ê°œ ì²­í¬")
        
        return {
            "blocks": doc_state.get("blocks", []),
            "statistics": {
                "total_blocks": doc_state.get("total_blocks", 0),
                "block_breakdown": {
                    "text": doc_state.get("text_blocks", 0),
                    "table": doc_state.get("table_blocks", 0),
                    "image": doc_state.get("image_blocks", 0)
                }
            },
            "keywords": doc_state.get("keywords", []),
            "summary": doc_state.get("summary", ""),
            "main_topics": doc_state.get("main_topics", []),
            "vectordb_uploaded": upload_to_vectordb
        }
    
    async def _step2_test_design(
        self, 
        doc_result: Dict[str, Any], 
        user_prompt: str, 
        difficulty: str
    ) -> Dict[str, Any]:
        """2ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ì„¤ê³„"""
        
        print("  ğŸ¯ í…ŒìŠ¤íŠ¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì¤‘...")
        
        design_input = {
            "keywords": doc_result["keywords"],
            "document_summary": doc_result["summary"],
            "document_topics": doc_result["main_topics"],
            "user_prompt": user_prompt,
            "difficulty": difficulty,
            "test_type": "mixed",
            "time_limit": 60
        }
        
        design_state = await self.test_designer.execute(design_input)
        
        if design_state.get("status") != "completed":
            raise Exception("í…ŒìŠ¤íŠ¸ ì„¤ê³„ ì‹¤íŒ¨")
        
        # BaseAgentì˜ execute ë©”ì†Œë“œì—ì„œ ê²°ê³¼ëŠ” intermediate_resultsì— ì €ì¥ë¨
        result = design_state.get("output") or design_state.get("intermediate_results", {})
        print(f"  âœ… ì„¤ê³„ ì™„ë£Œ: {result['test_config']['num_questions']}ë¬¸ì œ")
        
        return result
    
    async def _step3_question_generation(
        self, 
        doc_result: Dict[str, Any], 
        design_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """3ë‹¨ê³„: GPT-4o Visionìœ¼ë¡œ ë¬¸ì œ ìƒì„±"""
        
        print("  ğŸ¤– GPT-4o Vision ë¬¸ì œ ìƒì„± ì¤‘...")
        
        test_config = design_result["test_config"]
        test_summary = design_result["test_summary"]
        
        # ë¸”ë¡ë“¤ì„ Vision ë©”ì‹œì§€ë¡œ ë³€í™˜
        vision_chunks = self._prepare_vision_chunks(doc_result["blocks"])
        
        all_questions = []
        target_objective = test_config["num_objective"]
        target_subjective = test_config["num_subjective"]
        
        generated_objective = 0
        generated_subjective = 0
        
        for i, chunk in enumerate(vision_chunks):
            if generated_objective >= target_objective and generated_subjective >= target_subjective:
                break
            
            print(f"    ğŸ“ ì²­í¬ {i+1}/{len(vision_chunks)} ì²˜ë¦¬ ì¤‘...")
            
            # ë‚¨ì€ ë¬¸ì œ ìˆ˜ ê³„ì‚°
            remaining_obj = max(0, target_objective - generated_objective)
            remaining_subj = max(0, target_subjective - generated_subjective)
            
            if remaining_obj == 0 and remaining_subj == 0:
                break
            
            # ì²­í¬ë³„ ë¶„ë°°
            chunk_obj = min(remaining_obj, max(1, remaining_obj // (len(vision_chunks) - i)))
            chunk_subj = min(remaining_subj, max(1, remaining_subj // (len(vision_chunks) - i)))
            
            if chunk_obj == 0 and chunk_subj == 0:
                continue
            
            try:
                # GPT-4o Visionìœ¼ë¡œ ë¬¸ì œ ìƒì„±
                generator = QuestionGenerator()
                questions = generator._generate_question(
                    messages=chunk["messages"],
                    source=os.path.basename(doc_result.get("pdf_path", "document")),
                    page=str(chunk["metadata"]["page"]),
                    num_objective=chunk_obj,
                    num_subjective=chunk_subj
                )
                
                if questions:
                    all_questions.extend(questions)
                    
                    # ìƒì„±ëœ ë¬¸ì œ ìˆ˜ ì—…ë°ì´íŠ¸
                    for q in questions:
                        if q.get("type") == "OBJECTIVE":
                            generated_objective += 1
                        else:
                            generated_subjective += 1
                    
                    print(f"      âœ… {len(questions)}ê°œ ë¬¸ì œ ìƒì„±")
                
            except Exception as e:
                print(f"      âš ï¸ ì²­í¬ {i+1} ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
                continue
        
        print(f"  âœ… ì´ {len(all_questions)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")
        print(f"    - ê°ê´€ì‹: {generated_objective}ê°œ")
        print(f"    - ì£¼ê´€ì‹: {generated_subjective}ê°œ")
        
        return {
            "questions": all_questions,
            "statistics": {
                "total_questions": len(all_questions),
                "objective_questions": generated_objective,
                "subjective_questions": generated_subjective,
                "target_objective": target_objective,
                "target_subjective": target_subjective
            },
            "test_config": test_config
        }
    
    def _prepare_vision_chunks(self, blocks: List[Dict]) -> List[Dict]:
        """ë¸”ë¡ë“¤ì„ Vision APIìš© ì²­í¬ë¡œ ë³€í™˜"""
        generator = QuestionGenerator()
        return generator._blocks_to_vision_chunks(blocks)
    
    async def _upload_to_vectordb(self, blocks: List[Dict], collection_name: str) -> int:
        """VectorDBì— ë¸”ë¡ë“¤ ì—…ë¡œë“œ"""
        uploaded_count = 0
        
        for i, block in enumerate(blocks):
            try:
                # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
                content = self._extract_text_from_block(block)
                if not content:
                    continue
                
                # ì²­í¬ ê°ì²´ ìƒì„±
                chunk_obj = {
                    "chunk_id": f"{collection_name}_block_{i}",
                    "chunk_type": block.get("type", "unknown"),
                    "section_title": block.get("title", ""),
                    "source_text": content,
                    "project": collection_name,
                    "source": f"{collection_name}.pdf",
                    "page": str(block.get("metadata", {}).get("page", "N/A"))
                }
                
                # ë²¡í„° ì„ë² ë”© ìƒì„±
                vector = self.embedding_model.encode(content).tolist()
                
                # ì—…ë¡œë“œ
                upload_chunk_to_collection(chunk_obj, vector, collection_name)
                uploaded_count += 1
                
            except Exception as e:
                print(f"    âš ï¸ ë¸”ë¡ {i} ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        return uploaded_count
    
    def _extract_text_from_block(self, block: Dict) -> str:
        """ë¸”ë¡ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        block_type = block.get("type", "")
        content = block.get("content", "")
        
        if block_type in ["paragraph", "heading", "section"] and content:
            return str(content)
        elif block_type == "table" and isinstance(content, dict):
            # í‘œ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            return self._table_to_text(content)
        
        return ""
    
    def _table_to_text(self, table_data: Dict) -> str:
        """í‘œ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if not isinstance(table_data, dict) or "data" not in table_data:
            return ""
        
        headers = table_data.get("headers", [])
        data = table_data.get("data", [])
        
        text_parts = []
        if headers:
            text_parts.append(" ".join(str(h) for h in headers))
        
        for row in data:
            text_parts.append(" ".join(str(cell) for cell in row))
        
        return " ".join(text_parts)
    
    async def _save_results(self, result: Dict[str, Any], collection_name: str):
        """ê²°ê³¼ ì €ì¥"""
        output_dir = "data/outputs"
        os.makedirs(output_dir, exist_ok=True)
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥
        result_path = os.path.join(output_dir, f"{collection_name}_test_generation_result.json")
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        # ë¬¸ì œë§Œ ë³„ë„ ì €ì¥
        questions_path = os.path.join(output_dir, f"{collection_name}_questions.json")
        with open(questions_path, 'w', encoding='utf-8') as f:
            json.dump(result["questions"], f, ensure_ascii=False, indent=2)
        
        print(f"  ğŸ’¾ ê²°ê³¼ ì €ì¥: {result_path}")
        print(f"  ğŸ’¾ ë¬¸ì œ ì €ì¥: {questions_path}")


# í¸ì˜ í•¨ìˆ˜
async def generate_test_from_document(
    pdf_path: str,
    user_prompt: str,
    collection_name: str = None,
    difficulty: str = "medium",
    upload_to_vectordb: bool = True
) -> Dict[str, Any]:
    """
    ë¬¸ì„œë¡œë¶€í„° í…ŒìŠ¤íŠ¸ ìƒì„± í¸ì˜ í•¨ìˆ˜
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        user_prompt: ì‚¬ìš©ì ìš”ì²­
        collection_name: ì»¬ë ‰ì…˜ëª…
        difficulty: ë‚œì´ë„
        upload_to_vectordb: VectorDB ì—…ë¡œë“œ ì—¬ë¶€
        
    Returns:
        í…ŒìŠ¤íŠ¸ ìƒì„± ê²°ê³¼
    """
    pipeline = TestGenerationPipeline()
    return await pipeline.run_complete_workflow(
        pdf_path, user_prompt, collection_name, difficulty, upload_to_vectordb
    )