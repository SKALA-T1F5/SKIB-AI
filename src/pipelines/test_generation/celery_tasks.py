"""
Test Generation Pipelineìš© Celery Task - Question Generation
- Redisì—ì„œ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
- QuestionGeneratorAgentë¡œ ë¬¸ì œ ìƒì„±
- Redisì— ë¬¸ì œ ì €ì¥
- LangGraph Stateìš© í’ˆì§ˆ ì ìˆ˜ ë°˜í™˜
"""

import logging
from typing import Any, Dict

from config.celery_app import celery_app

logger = logging.getLogger(__name__)


@celery_app.task(
    bind=True,
    autoretry_for=(Exception,),
    retry_kwargs={"max_retries": 2, "countdown": 30},
    name="test_generation.question_generation",
)
def question_generation_task(
    self,
    pipeline_id: str,
    batch_id: int,
    target_questions: Dict[str, int],  # {"objective": 3, "subjective": 2}
    document_metadata: Dict[str, Any],
) -> Dict[str, Any]:
    """
    ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¬¸ì œ ìƒì„± Celery Task

    Args:
        pipeline_id: Pipeline ê³ ìœ  ID
        batch_id: ë°°ì¹˜ ID
        target_questions: ìƒì„±í•  ë¬¸ì œ ìˆ˜
        document_metadata: ë¬¸ì„œ ë©”íƒ€ë°ì´í„°

    Returns:
        Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼ ë° í’ˆì§ˆ ì ìˆ˜
    """
    task_id = self.request.id
    logger.info(f"ğŸ¤– Question Generation ì‹œì‘: Task {task_id}, Batch {batch_id}")

    try:
        # 1. Redisì—ì„œ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
        import asyncio

        from db.redisDB.testgen_session_manager import load_batch_contexts

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            contexts = loop.run_until_complete(
                load_batch_contexts(pipeline_id, batch_id)
            )
        finally:
            loop.close()

        if not contexts:
            raise Exception(f"ë°°ì¹˜ {batch_id}ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        logger.info(f"ğŸ“‹ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ: {len(contexts)}ê°œ")

        # 2. ë¬¸ì œ ìƒì„±
        from src.agents.question_generator.agent import generate_questions_for_batch

        result = generate_questions_for_batch(
            contexts=contexts,
            target_questions=target_questions,
            document_metadata=document_metadata,
        )

        if result["status"] != "success":
            raise Exception(f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")

        questions = result["questions"]
        quality_score = result["metadata"]["quality_score"]

        # 3. Redisì— ìƒì„±ëœ ë¬¸ì œ ì €ì¥
        from db.redisDB.testgen_session_manager import save_batch_questions

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            questions_saved = loop.run_until_complete(
                save_batch_questions(pipeline_id, batch_id, questions)
            )
        finally:
            loop.close()

        if not questions_saved:
            logger.warning(
                f"âš ï¸ ë¬¸ì œ Redis ì €ì¥ ì‹¤íŒ¨ (Pipeline: {pipeline_id}, Batch: {batch_id})"
            )

        # 4. ë°°ì¹˜ ìš”ì•½ ì €ì¥ (LangGraph ì¡°ê±´ë¶€ ë¶„ê¸°ìš©)
        from db.redisDB.testgen_session_manager import save_batch_summary

        batch_summary = {
            "batch_id": batch_id,
            "status": "completed",
            "questions_generated": len(questions),
            "average_quality": quality_score,
            "target_objective": target_questions.get("objective", 0),
            "target_subjective": target_questions.get("subjective", 0),
            "actual_objective": result["metadata"]["objective_count"],
            "actual_subjective": result["metadata"]["subjective_count"],
            "processing_time": getattr(self.request, "processing_time", None),
            "contexts_used": len(contexts),
        }

        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            loop.run_until_complete(
                save_batch_summary(pipeline_id, batch_id, batch_summary)
            )
        finally:
            loop.close()

        # 5. ì„±ê³µ ê²°ê³¼ ë°˜í™˜
        logger.info(
            f"âœ… Question Generation ì™„ë£Œ: {len(questions)}ê°œ ë¬¸ì œ, í’ˆì§ˆ: {quality_score:.3f}"
        )

        return {
            "status": "success",
            "pipeline_id": pipeline_id,
            "batch_id": batch_id,
            "questions_generated": len(questions),
            "quality_score": quality_score,
            "target_questions": target_questions,
            "actual_questions": {
                "objective": result["metadata"]["objective_count"],
                "subjective": result["metadata"]["subjective_count"],
            },
            "task_id": task_id,
        }

    except Exception as e:
        logger.error(f"âŒ Question Generation ì‹¤íŒ¨ (Batch {batch_id}): {e}")

        # ì¬ì‹œë„ ë¡œì§
        if self.request.retries < 2:
            logger.info(f"ğŸ”„ ì¬ì‹œë„ ì˜ˆì•½ ({self.request.retries + 1}/2)")
            raise self.retry(countdown=30 * (self.request.retries + 1))

        # ìµœì¢… ì‹¤íŒ¨
        return {
            "status": "failed",
            "pipeline_id": pipeline_id,
            "batch_id": batch_id,
            "questions_generated": 0,
            "quality_score": 0.0,
            "error": str(e),
            "task_id": task_id,
        }


@celery_app.task(bind=True, name="test_generation.regenerate_questions")
def regenerate_questions_task(
    self,
    pipeline_id: str,
    batch_id: int,
    failed_questions_info: Dict[str, Any],
    retry_strategy: str = "different_approach",
) -> Dict[str, Any]:
    """
    ì‹¤íŒ¨í•œ ë¬¸ì œ ì¬ìƒì„± Task

    Args:
        pipeline_id: Pipeline ê³ ìœ  ID
        batch_id: ë°°ì¹˜ ID
        failed_questions_info: ì‹¤íŒ¨í•œ ë¬¸ì œ ì •ë³´
        retry_strategy: ì¬ì‹œë„ ì „ëµ

    Returns:
        Dict: ì¬ìƒì„± ê²°ê³¼
    """
    task_id = self.request.id
    logger.info(f"ğŸ”„ Question Regeneration ì‹œì‘: Task {task_id}, Batch {batch_id}")

    try:
        # ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
        failed_questions_info.get("reason", "low_quality")
        target_questions = failed_questions_info.get("target_questions", {})

        # ë‹¤ë¥¸ ì „ëµ ì ìš©
        if retry_strategy == "different_approach":
            # ë” ê´€ëŒ€í•œ í’ˆì§ˆ ê¸°ì¤€ ì ìš©í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
            target_questions = {
                "objective": max(target_questions.get("objective", 0) - 1, 1),
                "subjective": max(target_questions.get("subjective", 0) - 1, 1),
            }

        # ê¸°ë³¸ ë¬¸ì œ ìƒì„± Task ì¬í˜¸ì¶œ
        return question_generation_task(
            pipeline_id=pipeline_id,
            batch_id=batch_id,
            target_questions=target_questions,
            document_metadata=failed_questions_info.get("document_metadata", {}),
        )

    except Exception as e:
        logger.error(f"âŒ Question Regeneration ì‹¤íŒ¨: {e}")
        return {
            "status": "failed",
            "pipeline_id": pipeline_id,
            "batch_id": batch_id,
            "error": str(e),
            "task_id": task_id,
        }
