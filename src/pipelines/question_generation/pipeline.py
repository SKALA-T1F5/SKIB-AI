"""
Question Generation Pipeline
ë¬¸ì œ ìƒì„± ì—ì´ì „íŠ¸ë§Œì„ ìœ„í•œ ë…ë¦½ì ì¸ íŒŒì´í”„ë¼ì¸

ê¸°ëŠ¥:
- íŒŒì‹±ëœ ë¸”ë¡(í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, í‘œ)ì„ ì‚¬ìš©í•œ ë¬¸ì œ ìƒì„±
- Gemini Visionì„ í™œìš©í•œ ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì œ ìƒì„±
- í…ŒìŠ¤íŠ¸ ì„¤ì •ì— ë”°ë¥¸ ë§ì¶¤í˜• ë¬¸ì œ ìƒì„±
- ìƒì„±ëœ ë¬¸ì œ ì €ì¥ ë° ê´€ë¦¬
"""

import os
import json
import time
from typing import Dict, Any, List, Optional
from datetime import datetime
from src.agents.question_generator.agent import QuestionGeneratorAgent


class QuestionGenerationPipeline:
    """ë¬¸ì œ ìƒì„± ì „ìš© íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, collection_name: str = None):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ëª… (ì´ë¯¸ì§€ ê²½ë¡œ ê²°ì •)
        """
        self.collection_name = collection_name
        self.question_generator = None
    
    def run(
        self,
        blocks: List[Dict],
        num_objective: int = 5,
        num_subjective: int = 3,
        source_file: str = "document.pdf",
        keywords: List[str] = None,
        main_topics: List[str] = None,
        summary: str = "",
        test_config: Dict[str, Any] = None,
        save_results: bool = True
    ) -> Dict[str, Any]:
        """
        ë¬¸ì œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            blocks: ë¬¸ì„œ ë¸”ë¡ë“¤ (íŒŒì‹±ëœ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, í‘œ)
            num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
            num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
            source_file: ì›ë³¸ íŒŒì¼ëª…
            keywords: í‚¤ì›Œë“œ ëª©ë¡
            main_topics: ì£¼ìš” ì£¼ì œ ëª©ë¡
            summary: ë¬¸ì„œ ìš”ì•½
            test_config: í…ŒìŠ¤íŠ¸ ì„¤ì • (ì˜µì…˜)
            save_results: ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            
        Returns:
            Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
        """
        start_time = time.time()
        
        print("ğŸ¤– Question Generation Pipeline ì‹œì‘")
        print(f"ğŸ“„ ì›ë³¸ íŒŒì¼: {source_file}")
        print(f"ğŸ“¦ ì»¬ë ‰ì…˜: {self.collection_name or 'default'}")
        print(f"ğŸ“ ì´ ë¸”ë¡: {len(blocks)}ê°œ")
        print(f"ğŸ¯ ëª©í‘œ ë¬¸ì œ: ê°ê´€ì‹ {num_objective}ê°œ, ì£¼ê´€ì‹ {num_subjective}ê°œ")
        if keywords:
            print(f"ğŸ”‘ í‚¤ì›Œë“œ: {len(keywords)}ê°œ")
        if main_topics:
            print(f"ğŸ“‹ ì£¼ì œ: {len(main_topics)}ê°œ")
        print("=" * 60)
        
        try:
            # QuestionGenerator ì´ˆê¸°í™”
            self.question_generator = QuestionGeneratorAgent(self.collection_name)
            
            # ë¬¸ì œ ìƒì„± ì‹¤í–‰
            print("\nğŸ”„ GPT-4 Visionìœ¼ë¡œ ë¬¸ì œ ìƒì„± ì¤‘...")
            print(f"ğŸ” VectorDB ê²€ìƒ‰: {'í™œì„±í™”' if self.collection_name else 'ë¹„í™œì„±í™”'}")
            generation_result = self.question_generator.generate_questions_from_blocks(
                blocks=blocks,
                num_objective=num_objective,
                num_subjective=num_subjective,
                source_file=source_file,
                keywords=keywords or [],
                main_topics=main_topics or [],
                summary=summary,
                test_config=test_config,
                use_vectordb_search=bool(self.collection_name)
            )
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ êµ¬ì„±
            pipeline_result = {
                "pipeline_info": {
                    "pipeline_type": "question_generation",
                    "source_file": source_file,
                    "collection_name": self.collection_name,
                    "total_blocks": len(blocks),
                    "target_objective": num_objective,
                    "target_subjective": num_subjective,
                    "processing_time": round(processing_time, 2),
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                },
                "input_data": {
                    "blocks_count": len(blocks),
                    "blocks_breakdown": self._analyze_blocks(blocks),
                    "keywords": keywords or [],
                    "main_topics": main_topics or [],
                    "summary": summary,
                    "test_config": test_config
                },
                "generation_result": generation_result,
                "status": generation_result.get("status", "unknown")
            }
            
            # ê²°ê³¼ ì €ì¥
            if save_results and generation_result.get("status") == "completed":
                saved_files = self._save_results(pipeline_result)
                pipeline_result["saved_files"] = saved_files
            
            # ê²°ê³¼ ì¶œë ¥
            if generation_result.get("status") == "completed":
                print(f"\nâœ… ë¬¸ì œ ìƒì„± ì™„ë£Œ!")
                print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
                print(f"ğŸ“Š ìƒì„±ëœ ë¬¸ì œ: {generation_result.get('total_questions', 0)}ê°œ")
                print(f"   - ê°ê´€ì‹: {generation_result.get('objective_count', 0)}ê°œ")
                print(f"   - ì£¼ê´€ì‹: {generation_result.get('subjective_count', 0)}ê°œ")
                if save_results:
                    print(f"ğŸ’¾ ì €ì¥ëœ íŒŒì¼: {len(pipeline_result.get('saved_files', []))}ê°œ")
            else:
                print(f"\nâŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨!")
                if generation_result.get("error"):
                    print(f"ì˜¤ë¥˜: {generation_result['error']}")
            
            return pipeline_result
            
        except Exception as e:
            print(f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "pipeline_info": {
                    "pipeline_type": "question_generation",
                    "source_file": source_file,
                    "collection_name": self.collection_name,
                    "processing_time": round(time.time() - start_time, 2),
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                },
                "input_data": {
                    "blocks_count": len(blocks),
                    "keywords": keywords or [],
                    "main_topics": main_topics or []
                },
                "generation_result": {},
                "status": "failed",
                "error": str(e)
            }
    
    def run_from_analysis_result(
        self,
        analysis_result_file: str,
        num_objective: int = 5,
        num_subjective: int = 3,
        test_config_file: str = None,
        save_results: bool = True
    ) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ë¡œë¶€í„° ë¬¸ì œ ìƒì„± ì‹¤í–‰
        
        Args:
            analysis_result_file: ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ
            num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
            num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
            test_config_file: í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì˜µì…˜)
            save_results: ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            
        Returns:
            Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
        """
        try:
            # ë¶„ì„ ê²°ê³¼ ë¡œë“œ
            with open(analysis_result_file, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            
            analysis_result = analysis_data.get('analysis_result', {})
            
            # í…ŒìŠ¤íŠ¸ ì„¤ì • ë¡œë“œ (ì˜µì…˜)
            test_config = None
            if test_config_file and os.path.exists(test_config_file):
                with open(test_config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                    test_config = config_data.get('test_config', {})
                    
                    # í…ŒìŠ¤íŠ¸ ì„¤ì •ì—ì„œ ë¬¸ì œ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
                    if 'num_objective' in test_config:
                        num_objective = test_config['num_objective']
                    if 'num_subjective' in test_config:
                        num_subjective = test_config['num_subjective']
            
            # ì»¬ë ‰ì…˜ëª… ì„¤ì •
            pipeline_info = analysis_data.get('pipeline_info', {})
            collection_name = pipeline_info.get('collection_name')
            if collection_name:
                self.collection_name = collection_name
            
            return self.run(
                blocks=analysis_result.get('blocks', []),
                num_objective=num_objective,
                num_subjective=num_subjective,
                source_file=pipeline_info.get('pdf_path', 'document.pdf'),
                keywords=analysis_result.get('keywords', []),
                main_topics=analysis_result.get('main_topics', []),
                summary=analysis_result.get('summary', ''),
                test_config=test_config,
                save_results=save_results
            )
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
            return {
                "pipeline_info": {
                    "pipeline_type": "question_generation",
                    "analysis_file": analysis_result_file,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                },
                "status": "failed",
                "error": f"ë¶„ì„ ê²°ê³¼ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {str(e)}"
            }
    
    def _analyze_blocks(self, blocks: List[Dict]) -> Dict[str, int]:
        """ë¸”ë¡ ìœ í˜•ë³„ ë¶„ì„"""
        breakdown = {"text": 0, "table": 0, "image": 0, "other": 0}
        
        for block in blocks:
            block_type = block.get("type", "other")
            if block_type in ["paragraph", "heading", "section"]:
                breakdown["text"] += 1
            elif block_type == "table":
                breakdown["table"] += 1
            elif block_type == "image":
                breakdown["image"] += 1
            else:
                breakdown["other"] += 1
        
        return breakdown
    
    def _save_results(self, pipeline_result: Dict[str, Any]) -> List[str]:
        """ê²°ê³¼ íŒŒì¼ ì €ì¥"""
        saved_files = []
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        source_name = os.path.splitext(os.path.basename(
            pipeline_result["pipeline_info"]["source_file"]
        ))[0]
        
        try:
            generation_result = pipeline_result["generation_result"]
            
            # Collection ëª… ê¸°ë°˜ ë””ë ‰í† ë¦¬ êµ¬ì¡°
            collection_dir = self.collection_name or "default"
            
            # ìƒì„±ëœ ë¬¸ì œ ì €ì¥
            if generation_result.get("questions"):
                questions_dir = f"data/outputs/generated_questions/{collection_dir}"
                os.makedirs(questions_dir, exist_ok=True)
                
                questions_data = {
                    "test_info": {
                        "source_file": pipeline_result["pipeline_info"]["source_file"],
                        "collection_name": pipeline_result["pipeline_info"]["collection_name"],
                        "generation_date": datetime.now().isoformat(),
                        "test_type": "auto_generated"
                    },
                    "question_summary": {
                        "total_questions": len(generation_result["questions"]),
                        "objective_questions": generation_result.get("objective_count", 0),
                        "subjective_questions": generation_result.get("subjective_count", 0)
                    },
                    "questions": generation_result["questions"],
                    "pipeline_info": pipeline_result["pipeline_info"],
                    "input_data": pipeline_result["input_data"]
                }
                
                questions_file = f"{questions_dir}/{source_name}_questions_{timestamp}.json"
                with open(questions_file, 'w', encoding='utf-8') as f:
                    json.dump(questions_data, f, ensure_ascii=False, indent=2)
                saved_files.append(questions_file)
                print(f"ğŸ’¾ ìƒì„±ëœ ë¬¸ì œ ì €ì¥: {questions_file}")
            
            # ì „ì²´ ê²°ê³¼ ì €ì¥
            results_dir = "data/outputs/question_generation_results"
            os.makedirs(results_dir, exist_ok=True)
            
            result_file = f"{results_dir}/{source_name}_question_generation_{timestamp}.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(pipeline_result, f, ensure_ascii=False, indent=2)
            saved_files.append(result_file)
            print(f"ğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥: {result_file}")
            
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return saved_files


def run_question_generation(
    blocks: List[Dict],
    num_objective: int = 5,
    num_subjective: int = 3,
    collection_name: str = None,
    source_file: str = "document.pdf"
) -> Dict[str, Any]:
    """
    ë¬¸ì œ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í¸ì˜ í•¨ìˆ˜
    
    Args:
        blocks: ë¬¸ì„œ ë¸”ë¡ë“¤
        num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
        num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
        collection_name: ì»¬ë ‰ì…˜ëª…
        source_file: ì›ë³¸ íŒŒì¼ëª…
        
    Returns:
        Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
    """
    pipeline = QuestionGenerationPipeline(collection_name)
    return pipeline.run(blocks, num_objective, num_subjective, source_file)


def run_question_generation_from_file(
    analysis_result_file: str,
    num_objective: int = 5,
    num_subjective: int = 3,
    test_config_file: str = None
) -> Dict[str, Any]:
    """
    ë¶„ì„ ê²°ê³¼ íŒŒì¼ë¡œë¶€í„° ë¬¸ì œ ìƒì„± ì‹¤í–‰ í¸ì˜ í•¨ìˆ˜
    
    Args:
        analysis_result_file: ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
        num_objective: ê°ê´€ì‹ ë¬¸ì œ ìˆ˜
        num_subjective: ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜
        test_config_file: í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        
    Returns:
        Dict: ë¬¸ì œ ìƒì„± ê²°ê³¼
    """
    pipeline = QuestionGenerationPipeline()
    return pipeline.run_from_analysis_result(
        analysis_result_file, num_objective, num_subjective, test_config_file
    )


if __name__ == "__main__":
    import glob
    import os
    import json
    
    print("ğŸ¤– Question Generation Pipeline")
    print("=" * 50)
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ collection ëª©ë¡ í‘œì‹œ
    keywords_base_dir = "data/outputs/keywords_summary"
    configs_base_dir = "data/outputs/test_configs"
    analysis_base_dir = "data/outputs/document_analysis"
    
    if not os.path.exists(keywords_base_dir):
        print("âŒ keywords_summary ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œ ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        exit(1)
    
    collections = [d for d in os.listdir(keywords_base_dir) if os.path.isdir(os.path.join(keywords_base_dir, d))]
    if not collections:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ collectionì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œ ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        exit(1)
    
    print("ì‚¬ìš© ê°€ëŠ¥í•œ Collection:")
    for i, collection in enumerate(collections, 1):
        # í‚¤ì›Œë“œ, í…ŒìŠ¤íŠ¸ ì„¤ì •, ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê°œìˆ˜ í™•ì¸
        keyword_files = glob.glob(f"{keywords_base_dir}/{collection}/*_keywords_summary_*.json")
        config_files = glob.glob(f"{configs_base_dir}/{collection}/*_test_config_*.json") if os.path.exists(f"{configs_base_dir}/{collection}") else []
        analysis_files = glob.glob(f"{analysis_base_dir}/{collection}/*_analysis_result_*.json") if os.path.exists(f"{analysis_base_dir}/{collection}") else []
        print(f"  {i}. {collection} (í‚¤ì›Œë“œ: {len(keyword_files)}ê°œ, í…ŒìŠ¤íŠ¸ì„¤ì •: {len(config_files)}ê°œ, ë¶„ì„ê²°ê³¼: {len(analysis_files)}ê°œ)")
    
    # Collection ì„ íƒ
    try:
        choice = int(input(f"\nì‚¬ìš©í•  Collection ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{len(collections)}): "))
        if 1 <= choice <= len(collections):
            selected_collection = collections[choice - 1]
            print(f"âœ… ì„ íƒëœ Collection: {selected_collection}")
        else:
            print("âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
            exit(1)
    except ValueError:
        print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        exit(1)
    
    # í‚¤ì›Œë“œ íŒŒì¼ ì°¾ê¸°
    collection_keywords_dir = os.path.join(keywords_base_dir, selected_collection)
    keyword_files = glob.glob(f"{collection_keywords_dir}/*_keywords_summary_*.json")
    
    if not keyword_files:
        print(f"âŒ {selected_collection} collectionì— í‚¤ì›Œë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)
    
    latest_keywords_file = sorted(keyword_files)[-1]
    print(f"ğŸ“„ í‚¤ì›Œë“œ íŒŒì¼: {os.path.basename(latest_keywords_file)}")
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì°¾ê¸° (ì„ íƒì )
    collection_configs_dir = os.path.join(configs_base_dir, selected_collection)
    config_file = None
    if os.path.exists(collection_configs_dir):
        config_files = glob.glob(f"{collection_configs_dir}/*_test_config_*.json")
        if config_files:
            config_file = sorted(config_files)[-1]
            print(f"âš™ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼: {os.path.basename(config_file)}")
        else:
            print("âš ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        print("âš ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í…ŒìŠ¤íŠ¸ ì„¤ê³„ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    # ë¬¸ì œ ìˆ˜ ì…ë ¥
    print("\në¬¸ì œ ìƒì„± ì„¤ì •:")
    try:
        num_objective = int(input("ê°ê´€ì‹ ë¬¸ì œ ìˆ˜ (ê¸°ë³¸ê°’: 5): ") or "5")
        num_subjective = int(input("ì£¼ê´€ì‹ ë¬¸ì œ ìˆ˜ (ê¸°ë³¸ê°’: 3): ") or "3")
    except ValueError:
        print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        exit(1)
    
    print(f"\nğŸ”„ ë¬¸ì œ ìƒì„± ì‹œì‘...")
    print(f"ğŸ“¦ Collection: {selected_collection}")
    print(f"ğŸ¯ ëª©í‘œ: ê°ê´€ì‹ {num_objective}ê°œ, ì£¼ê´€ì‹ {num_subjective}ê°œ")
    print(f"ğŸ” VectorDB ê²€ìƒ‰: í™œì„±í™”")
    
    # ë¶„ì„ ê²°ê³¼ íŒŒì¼ì—ì„œ ë¸”ë¡ ë°ì´í„° ë¡œë“œ
    try:
        # í‚¤ì›Œë“œ íŒŒì¼ ë¡œë“œ
        with open(latest_keywords_file, 'r', encoding='utf-8') as f:
            keywords_data = json.load(f)
        content_analysis = keywords_data.get('content_analysis', {})
        
        # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        collection_analysis_dir = os.path.join(analysis_base_dir, selected_collection)
        blocks = []
        
        if os.path.exists(collection_analysis_dir):
            analysis_files = glob.glob(f"{collection_analysis_dir}/*_analysis_result_*.json")
            if analysis_files:
                latest_analysis_file = sorted(analysis_files)[-1]
                print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ íŒŒì¼: {os.path.basename(latest_analysis_file)}")
                
                with open(latest_analysis_file, 'r', encoding='utf-8') as f:
                    analysis_data = json.load(f)
                
                analysis_result = analysis_data.get('analysis_result', {})
                blocks = analysis_result.get('blocks', [])
                
                if not blocks:
                    print("âš ï¸ ë¸”ë¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¸”ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                    blocks = [
                        {
                            'type': 'paragraph',
                            'content': f"ë¬¸ì„œ ìš”ì•½: {content_analysis.get('summary', '')}",
                            'metadata': {'page': 1, 'source': 'keywords_summary'}
                        }
                    ]
            else:
                print("âš ï¸ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¸”ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                blocks = [
                    {
                        'type': 'paragraph',
                        'content': f"ë¬¸ì„œ ìš”ì•½: {content_analysis.get('summary', '')}",
                        'metadata': {'page': 1, 'source': 'keywords_summary'}
                    }
                ]
        else:
            print("âš ï¸ ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¸”ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            blocks = [
                {
                    'type': 'paragraph',
                    'content': f"ë¬¸ì„œ ìš”ì•½: {content_analysis.get('summary', '')}",
                    'metadata': {'page': 1, 'source': 'keywords_summary'}
                }
            ]
        
        print(f"ğŸ“ ì‚¬ìš©í•  ë¸”ë¡: {len(blocks)}ê°œ")
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = QuestionGenerationPipeline(collection_name=selected_collection)
        result = pipeline.run(
            blocks=blocks,
            num_objective=num_objective,
            num_subjective=num_subjective,
            source_file=keywords_data.get('document_info', {}).get('source_file', 'document.pdf'),
            keywords=content_analysis.get('keywords', []),
            main_topics=content_analysis.get('main_topics', []),
            summary=content_analysis.get('summary', ''),
            test_config=json.load(open(config_file, 'r', encoding='utf-8')).get('test_config') if config_file else None
        )
        
        print(f"\nìµœì¢… ê²°ê³¼: {result['status']}")
        
    except Exception as e:
        print(f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")