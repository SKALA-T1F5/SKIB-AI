#!/usr/bin/env python3
"""
í†µí•© PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
- í†µí•© íŒŒì„œ (Docling + ì„ íƒì  ìš”ì†Œ ì¶”ì¶œ)
- í‚¤ì›Œë“œ ì¶”ì¶œ ë° ìš”ì•½ (JSON ì¶œë ¥)
- ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±

ì‚¬ìš©ë²•:
python test_complete_pipeline.py
"""

import os
import json
import time
from typing import List, Dict
from src.agents.question_generator.unified_parser import parse_pdf_unified
from src.agents.question_generator.keyword_summary import extract_keywords_and_summary
from src.agents.question_generator.change_name import normalize_collection_name


def test_document(pdf_path: str, document_name: str) -> Dict:
    """ê°œë³„ ë¬¸ì„œ í…ŒìŠ¤íŠ¸"""
    print(f"\n{'='*60}")
    print(f"ğŸ”„ {document_name} í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“„ íŒŒì¼: {pdf_path}")
    print(f"{'='*60}")
    
    if not os.path.exists(pdf_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return None
    
    start_time = time.time()
    
    try:
        # 1. í†µí•© íŒŒì„œ ì‹¤í–‰
        print("\n1ï¸âƒ£ í†µí•© íŒŒì„œ ì‹¤í–‰ ì¤‘...")
        source_file = os.path.basename(pdf_path)
        collection_name = os.path.splitext(source_file)[0]
        
        normalized_name = normalize_collection_name(collection_name)
        blocks = parse_pdf_unified(pdf_path, normalized_name)
        
        # 2. ë¸”ë¡ ë¶„ì„
        text_blocks = [b for b in blocks if b.get('type') in ['paragraph', 'section', 'heading']]
        table_blocks = [b for b in blocks if b.get('type') == 'table']
        image_blocks = [b for b in blocks if b.get('type') == 'image']
        
        print(f"âœ… íŒŒì„œ ì™„ë£Œ: ì´ {len(blocks)}ê°œ ë¸”ë¡")
        print(f"   - í…ìŠ¤íŠ¸: {len(text_blocks)}ê°œ")
        print(f"   - í‘œ: {len(table_blocks)}ê°œ")
        print(f"   - ì´ë¯¸ì§€: {len(image_blocks)}ê°œ")
        
        # 3. í‚¤ì›Œë“œ ì¶”ì¶œ ë° ìš”ì•½
        print("\n2ï¸âƒ£ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ìš”ì•½ ì¤‘...")
        keywords_result = extract_keywords_and_summary(blocks, source_file)
        
        # 4. JSON íŒŒì¼ ì €ì¥
        output_dir = "data/outputs"
        os.makedirs(output_dir, exist_ok=True)
        
        output_filename = f"{normalized_name}.json"
        output_path = os.path.join(output_dir, output_filename)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(keywords_result, f, ensure_ascii=False, indent=2)
        
        processing_time = time.time() - start_time
        
        # 5. ê²°ê³¼ ìš”ì•½
        content_analysis = keywords_result.get('content_analysis', {})
        
        result = {
            "document_name": document_name,
            "file_path": pdf_path,
            "processing_time": round(processing_time, 2),
            "extraction_stats": {
                "total_blocks": len(blocks),
                "text_blocks": len(text_blocks),
                "table_blocks": len(table_blocks),
                "image_blocks": len(image_blocks)
            },
            "content_summary": {
                "summary": content_analysis.get('summary', '')[:100] + "..." if content_analysis.get('summary') else '',
                "main_topics_count": len(content_analysis.get('main_topics', [])),
                "key_concepts_count": len(content_analysis.get('key_concepts', [])),
                "technical_terms_count": len(content_analysis.get('technical_terms', []))
            },
            "output_file": output_path,
            "image_directory": f"data/images/{normalized_name}"
        }
        
        print(f"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
        print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        
        return result
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
            "document_name": document_name,
            "file_path": pdf_path,
            "error": str(e),
            "processing_time": time.time() - start_time
        }


def print_test_results(results: List[Dict]):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥"""
    print(f"\n{'='*80}")
    print("ğŸ“Š í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*80}")
    
    successful_tests = [r for r in results if r and 'error' not in r]
    failed_tests = [r for r in results if r and 'error' in r]
    
    print(f"âœ… ì„±ê³µ: {len(successful_tests)}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len(failed_tests)}ê°œ")
    print(f"â±ï¸  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {sum(r['processing_time'] for r in successful_tests) / len(successful_tests):.2f}ì´ˆ" if successful_tests else "")
    
    if successful_tests:
        print(f"\nğŸ“‹ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸:")
        for result in successful_tests:
            stats = result.get('extraction_stats', {})
            content = result.get('content_summary', {})
            
            print(f"\nğŸ”¹ {result['document_name']}")
            print(f"   ë¸”ë¡: {stats.get('total_blocks', 0)}ê°œ (í…ìŠ¤íŠ¸:{stats.get('text_blocks', 0)}, í‘œ:{stats.get('table_blocks', 0)}, ì´ë¯¸ì§€:{stats.get('image_blocks', 0)})")
            print(f"   í‚¤ì›Œë“œ: ì£¼ì œ {content.get('main_topics_count', 0)}ê°œ, ê°œë… {content.get('key_concepts_count', 0)}ê°œ, ìš©ì–´ {content.get('technical_terms_count', 0)}ê°œ")
            print(f"   ìš”ì•½: {content.get('summary', 'ìš”ì•½ ì—†ìŒ')}")
            print(f"   ì¶œë ¥: {result.get('output_file', 'N/A')}")
            print(f"   ì²˜ë¦¬ì‹œê°„: {result['processing_time']}ì´ˆ")
    
    if failed_tests:
        print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
        for result in failed_tests:
            print(f"   - {result['document_name']}: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ í†µí•© PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸í•  ë¬¸ì„œ ëª©ë¡
    test_documents = [
        {
            "name": "FBS UI ì •ì˜ì„œ",
            "path": "data/raw_docs/FBS_To-Be UIì •ì˜ì„œ_íŒë±…í‚¹_v0.66.pdf"
        }
    ]
    
    # ê²°ê³¼ ì €ì¥
    all_results = []
    total_start_time = time.time()
    
    # ê° ë¬¸ì„œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    for doc in test_documents:
        result = test_document(doc["path"], doc["name"])
        if result:
            all_results.append(result)
    
    total_time = time.time() - total_start_time
    
    # ì¢…í•© ê²°ê³¼ ì¶œë ¥
    print_test_results(all_results)
    
    # ì¢…í•© ê²°ê³¼ JSON ì €ì¥
    summary_result = {
        "test_info": {
            "test_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_processing_time": round(total_time, 2),
            "documents_tested": len(test_documents)
        },
        "results": all_results
    }
    
    summary_path = "data/outputs/complete_pipeline_test_summary.json"
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary_result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ ì¢…í•© ê²°ê³¼ ì €ì¥: {summary_path}")
    print(f"â±ï¸  ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
    print("\nğŸ‰ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()